# æ•°æ®æµæ°´çº¿ä¸èƒŒå‹æ§åˆ¶

æœ¬æ–‡æ¡£è§£é‡Š df2redis çš„æ•°æ®æµæ°´çº¿æ¶æ„ï¼Œä»¥åŠå¦‚ä½•å¤„ç† Dragonflyï¼ˆå¿«é€Ÿï¼‰å’Œ Redisï¼ˆè¾ƒæ…¢ï¼‰ä¹‹é—´çš„é€Ÿåº¦ä¸åŒ¹é…é—®é¢˜ã€‚

## é€Ÿåº¦ä¸åŒ¹é…é—®é¢˜

```
Dragonfly (æºç«¯)     df2redis (æµæ°´çº¿)     Redis Cluster (ç›®æ ‡ç«¯)
  100K ops/sec    â”€â”€â”€â”€â–º   ?????  â”€â”€â”€â”€â–º   10K ops/sec
     (å¿«é€Ÿ)                              (è¾ƒæ…¢)
```

**æŒ‘æˆ˜**ï¼šå¦‚æœæ²¡æœ‰é€‚å½“çš„ç¼“å†²å’ŒèƒŒå‹æ§åˆ¶ï¼š
- å†…å­˜è€—å°½ï¼ˆOOMï¼‰
- Goroutine çˆ†ç‚¸
- TCP ç¼“å†²åŒºæº¢å‡º

## æµæ°´çº¿æ¶æ„

<!-- ğŸ–¼ï¸ æ•°æ®æµæ°´çº¿æ¶æ„å›¾å ä½ç¬¦ -->
<!-- æ›¿æ¢ä¸ºï¼šdocs/images/architecture/data-pipeline.png -->
![æ•°æ®æµæ°´çº¿æ¶æ„](../../images/architecture/data-pipeline.png)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Dragonfly (å¿«é€Ÿç”Ÿäº§è€…)                         â”‚
â”‚                      ~100,000 ops/sec                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ RDB/Journal Stream
                                  â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   RDB/Journal Parser  â”‚
                      â”‚    (8 goroutines)     â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Parsed Entries
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Channel Buffer (èƒŒå‹æ§åˆ¶)                     â”‚
â”‚                                                                  â”‚
â”‚  entryChan := make(chan *RDBEntry, 2000000)                      â”‚
â”‚                                                                  â”‚
â”‚  å®¹é‡ï¼š2M æ¡ç›® Ã— 1KB/æ¡ç›® = æ¯ä¸ª FLOW 2GB                        â”‚
â”‚  æ€»è®¡ï¼š8 FLOWs Ã— 2GB = 16GB å†…å­˜                                 â”‚
â”‚                                                                  â”‚
â”‚  å½“ç¼“å†²åŒºæ»¡æ—¶ â†’ Parser é˜»å¡ â†’ Dragonfly å‡é€Ÿ                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Buffered Entries
                                  â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  æ‰¹æ¬¡ç´¯ç§¯å™¨           â”‚
                      â”‚                       â”‚
                      â”‚  æ”¶é›†æ¡ç›®ç›´åˆ°         â”‚
                      â”‚  è¾¾åˆ° batchSize       â”‚
                      â”‚  (é›†ç¾¤æ¨¡å¼ 20K)       â”‚
                      â”‚                       â”‚
                      â”‚  â° Ticker: 5000ms     â”‚
                      â”‚  (å¤‡ç”¨åˆ·æ–°)           â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Full Batch
                                  â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  å¹¶å‘é™åˆ¶å™¨           â”‚
                      â”‚                       â”‚
                      â”‚  Semaphore:           â”‚
                      â”‚  max 50 batches       â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Acquire Slot
                                  â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  æ‰¹æ¬¡å¤„ç†å™¨           â”‚
                      â”‚                       â”‚
                      â”‚  groupByNode()        â”‚
                      â”‚  â†’ 3 ä¸ªèŠ‚ç‚¹åˆ†ç»„       â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Grouped Commands
                                  â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Pipeline æ‰§è¡Œå™¨      â”‚
                      â”‚                       â”‚
                      â”‚  3 ä¸ª Pipeline        â”‚
                      â”‚  (æ¯ä¸ª ~666 ä¸ªå‘½ä»¤)   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â”‚ Redis Commands
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Redis Cluster (æ…¢é€Ÿæ¶ˆè´¹è€…)                       â”‚
â”‚                       ~10,000 ops/sec                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ç»„ä»¶è¯¦è§£

### 1. Channel ç¼“å†²åŒºï¼ˆèƒŒå‹æ§åˆ¶ï¼‰

**ç›®çš„**ï¼šå¸æ”¶çªå‘æµé‡ï¼Œå¹¶åœ¨ç›®æ ‡æ¯”æºæ…¢æ—¶æä¾›èƒŒå‹ã€‚

```go
type FlowWriter struct {
    entryChan chan *RDBEntry  // Buffered channel
}

func NewFlowWriter(flowID int) *FlowWriter {
    return &FlowWriter{
        entryChan: make(chan *RDBEntry, 2000000),  // 2M buffer
    }
}
```

#### èƒŒå‹å·¥ä½œåŸç†

```go
// ç”Ÿäº§è€…ï¼ˆParserï¼‰- ç¼“å†²åŒºæ»¡æ—¶é˜»å¡
func (p *Parser) Enqueue(entry *RDBEntry) {
    p.writer.entryChan <- entry  // å¦‚æœ Channel æ»¡äº†ä¼šé˜»å¡
}

// æ¶ˆè´¹è€…ï¼ˆWriterï¼‰- å§‹ç»ˆåœ¨æ’ç©º
func (w *FlowWriter) batchWriteLoop() {
    for entry := range w.entryChan {
        // Process entry
    }
}
```

**èƒŒå‹é“¾**ï¼š
```
Redis æ…¢ â†’ Writer æ…¢ â†’ Channel å¡«æ»¡ â†’ Parser é˜»å¡ â†’
TCP ç¼“å†²åŒºå¡«æ»¡ â†’ Dragonfly æ£€æµ‹åˆ°æ»¡ç¼“å†²åŒº â†’ Dragonfly å‡é€Ÿ
```

#### ç¼“å†²åŒºå¤§å°è®¾è®¡

```
å¹³å‡æ¡ç›®å¤§å°ï¼š1KB
ç¼“å†²åŒºå®¹é‡ï¼š2M æ¡ç›®
æ¯ä¸ª FLOW å†…å­˜ï¼š2M Ã— 1KB = 2GB
æ€»è®¡ï¼ˆ8 FLOWsï¼‰ï¼š16GB

ä¸ºä»€ä¹ˆæ˜¯ 2Mï¼Ÿ
- è¶³å¤Ÿå¤§ï¼šå¸æ”¶ 10-20 ç§’çš„çªå‘æµé‡
- è¶³å¤Ÿå°ï¼šé€‚åˆå…¸å‹æœåŠ¡å™¨å†…å­˜ï¼ˆ64-128GBï¼‰
```

### 2. æ‰¹æ¬¡ç´¯ç§¯å™¨

**ç›®çš„**ï¼šå°†æ¡ç›®æ”¶é›†åˆ°å¤§æ‰¹æ¬¡ä¸­ï¼Œä»¥å®ç°é«˜æ•ˆçš„ Pipeline æ‰§è¡Œã€‚

```go
func (fw *FlowWriter) batchWriteLoop() {
    batch := make([]*RDBEntry, 0, fw.batchSize)
    ticker := time.NewTicker(fw.flushInterval)
    defer ticker.Stop()

    for {
        select {
        case entry, ok := <-fw.entryChan:
            if !ok {
                // Channel closed, flush remaining
                if len(batch) > 0 {
                    fw.flushBatch(batch)
                }
                return
            }

            batch = append(batch, entry)

            // Flush when batch is full
            if len(batch) >= fw.batchSize {
                fw.flushBatch(batch)
                batch = make([]*RDBEntry, 0, fw.batchSize)
            }

        case <-ticker.C:
            // Periodic flush for incomplete batches
            if len(batch) > 0 {
                fw.flushBatch(batch)
                batch = make([]*RDBEntry, 0, fw.batchSize)
            }
        }
    }
}
```

#### æ‰¹å¤„ç†ç­–ç•¥

| æ¨¡å¼ | æ‰¹æ¬¡å¤§å° | åˆ·æ–°é—´éš” | åŸå›  |
|------|-----------|----------------|-----------|
| **é›†ç¾¤æ¨¡å¼** | 20,000 | 5000ms | Slot åˆ†ç»„éœ€è¦å¤§æ‰¹æ¬¡ |
| **å•æœºæ¨¡å¼** | 2,000 | 50ms | æ—  Slot ç¢ç‰‡ï¼Œä¼˜å…ˆè€ƒè™‘å»¶è¿Ÿ |

### 3. å¹¶å‘é™åˆ¶å™¨ï¼ˆä¿¡å·é‡ï¼‰

**ç›®çš„**ï¼šé˜²æ­¢è¿‡å¤šå¹¶å‘æ‰¹æ¬¡å‹å®ç³»ç»Ÿã€‚

```go
type FlowWriter struct {
    writeSemaphore chan struct{}  // Semaphore
    maxConcurrent  int
}

func NewFlowWriter(maxConcurrent int) *FlowWriter {
    return &FlowWriter{
        writeSemaphore: make(chan struct{}, maxConcurrent),
        maxConcurrent:  maxConcurrent,
    }
}

func (fw *FlowWriter) flushBatch(batch []*RDBEntry) {
    // Acquire semaphore slot (blocks if limit reached)
    fw.writeSemaphore <- struct{}{}

    // Process batch asynchronously
    go func(b []*RDBEntry) {
        defer func() { <-fw.writeSemaphore }()  // Release slot

        fw.writeBatchToRedis(b)
    }(batch)
}
```

#### å¹¶å‘è°ƒä¼˜

```
å•æœºæ¨¡å¼ï¼š
- maxConcurrent = 50ï¼ˆé«˜å¹¶è¡Œåº¦ï¼‰
- æ€» Goroutineï¼š50 Ã— 8 FLOWs = 400

é›†ç¾¤æ¨¡å¼ï¼š
- maxConcurrent = 400 / numFlows = 50
- æ€» Goroutineï¼š50 Ã— 8 FLOWs = 400
```

### 4. åŸºäºèŠ‚ç‚¹çš„åˆ†ç»„

è¯¦è§ [é›†ç¾¤è·¯ç”±ä¼˜åŒ–](cluster-routing.md)ã€‚

```go
func (fw *FlowWriter) groupByNode(batch []*RDBEntry) map[string][]*RDBEntry {
    groups := make(map[string][]*RDBEntry)

    for _, entry := range batch {
        slot := crc16(entry.Key) % 16384
        masterAddr := fw.clusterClient.MasterAddrForSlot(slot)
        groups[masterAddr] = append(groups[masterAddr], entry)
    }

    return groups  // 3 ä¸ªä¸»èŠ‚ç‚¹äº§ç”Ÿ 3 ä¸ªåˆ†ç»„
}
```

### 5. Pipeline æ‰§è¡Œ

```go
func (fw *FlowWriter) writeNodeGroup(masterAddr string, entries []*RDBEntry) {
    // Build commands
    cmds := make([][]interface{}, 0, len(entries))
    for _, entry := range entries {
        cmd := fw.buildCommand(entry)
        cmds = append(cmds, cmd)
    }

    // Execute pipeline
    conn := fw.clusterClient.GetConnectionForMaster(masterAddr)
    results, err := conn.Pipeline(cmds)

    // Handle results
    for i, result := range results {
        if isError(result) {
            log.Errorf("Command %d failed: %v", i, result)
        }
    }
}
```

## æµé‡æ§åˆ¶æœºåˆ¶

### 1. Channel é˜»å¡ï¼ˆä¸»è¦èƒŒå‹ï¼‰

```go
// å½“ Channel æ»¡æ—¶ï¼ŒParser goroutine é˜»å¡
func (p *Parser) parseRDBStream() {
    for {
        entry := p.readNextEntry()

        // è¿™ä¸€è¡Œåœ¨ Channel æ»¡æ—¶é˜»å¡
        p.writer.entryChan <- entry
    }
}
```

### 2. ä¿¡å·é‡é™åˆ¶ï¼ˆå¹¶å‘æ§åˆ¶ï¼‰

```go
// å½“ä¿¡å·é‡æ»¡æ—¶ï¼Œæ‰¹æ¬¡åˆ·æ–°ç­‰å¾…
func (fw *FlowWriter) flushBatch(batch []*RDBEntry) {
    // è¿™ä¸€è¡Œåœ¨æœ‰ maxConcurrent ä¸ªæ‰¹æ¬¡æ­£åœ¨å¤„ç†æ—¶é˜»å¡
    fw.writeSemaphore <- struct{}{}

    go fw.writeBatchToRedis(batch)
}
```

### 3. TCP ç¼“å†²ï¼ˆæ“ä½œç³»ç»Ÿçº§åˆ«èƒŒå‹ï¼‰

```go
// å¢åŠ  TCP æ¥æ”¶ç¼“å†²åŒºä»¥å¸æ”¶çªå‘
if tcpConn, ok := conn.(*net.TCPConn); ok {
    tcpConn.SetReadBuffer(10 * 1024 * 1024)  // 10MB
}
```

## æ€§èƒ½ç‰¹æ€§

### ååé‡

**å…¨é‡åŒæ­¥**ï¼š
```
Parser ååé‡ï¼š~150K ops/secï¼ˆ8 FLOWs Ã— æ¯ä¸ª 18Kï¼‰
Writer ååé‡ï¼š~100K ops/secï¼ˆå— Redis é™åˆ¶ï¼‰
ç¼“å†²åŒºå¸æ”¶å·®å¼‚
```

**ç¨³å®šåŒæ­¥**ï¼š
```
Journal é€Ÿç‡ï¼š~40K ops/secï¼ˆå…¸å‹å·¥ä½œè´Ÿè½½ï¼‰
Writer ååé‡ï¼š~100K ops/sec
æ— éœ€ç¼“å†²ï¼ŒChannel å‡ ä¹ä¿æŒç©ºé—²
```

### å»¶è¿Ÿ

**ç«¯åˆ°ç«¯**ï¼š
```
æ¡ç›®åˆ°è¾¾ â†’ Parser (0.1ms) â†’ Buffer (0ms) â†’ Accumulator (5000ms) â†’
Semaphore (10ms) â†’ Pipeline (20ms) â†’ Redis (5ms) = ~5035ms
```

**å…³é”®è·¯å¾„**ï¼šç´¯ç§¯å™¨ç­‰å¾…æ—¶é—´ï¼ˆé›†ç¾¤æ¨¡å¼ 5000msï¼‰

### å†…å­˜ä½¿ç”¨

```
Channel ç¼“å†²åŒºï¼š8 FLOWs Ã— 2GB = 16GB
æ‰¹æ¬¡æš‚å­˜ï¼š8 Ã— 20K Ã— 1KB = 160MB
æ€»è®¡ï¼š~16GBï¼ˆæ­£å¸¸è´Ÿè½½ä¸‹ï¼‰
```

## ç›‘æ§

### å…³é”®æŒ‡æ ‡

```go
// Channel åˆ©ç”¨ç‡
channelUtilization = len(entryChan) / cap(entryChan)

// Semaphore åˆ©ç”¨ç‡
semaphoreUtilization = len(writeSemaphore) / cap(writeSemaphore)

// æ‰¹æ¬¡ç´¯ç§¯æ—¶é—´
batchWaitTime = time.Since(batchStartTime)
```

### å¥åº·æŒ‡æ ‡

| æŒ‡æ ‡ | å¥åº· | è­¦å‘Š | ä¸¥é‡ |
|--------|---------|---------|----------|
| Channel åˆ©ç”¨ç‡ | <50% | 50-80% | >80% |
| Semaphore åˆ©ç”¨ç‡ | <70% | 70-90% | >90% |
| æ‰¹æ¬¡ç­‰å¾…æ—¶é—´ | <5s | 5-10s | >10s |

### Dashboard é›†æˆ

```go
// Export metrics to Prometheus
pipelineChannelUtilization.Set(float64(len(entryChan)) / float64(cap(entryChan)))
pipelineActiveBatches.Set(float64(len(writeSemaphore)))
pipelineBatchWaitTime.Observe(batchWaitTime.Seconds())
```

## æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šé«˜å†…å­˜ä½¿ç”¨ (>20GB)

**è¯Šæ–­**ï¼š
```bash
# Check channel depth
grep "channel.*full" log/replicate.log
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å‡å°‘ Channel ç¼“å†²åŒºå¤§å°ï¼ˆ2M â†’ 1Mï¼‰
2. å¢åŠ  Redis ç›®æ ‡å®¹é‡
3. å‡å°‘æ‰¹æ¬¡å¤§å°ï¼ˆ20K â†’ 10Kï¼‰

### é—®é¢˜ï¼šä½ååé‡ (<10K ops/sec)

**è¯Šæ–­**ï¼š
```bash
# Check batch sizes
grep "Flushing batch" log/replicate.log | awk '{print $NF}'
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. å¢åŠ æ‰¹æ¬¡å¤§å°ï¼ˆ2K â†’ 20Kï¼Œé›†ç¾¤æ¨¡å¼ï¼‰
2. å¢åŠ  maxConcurrentï¼ˆ50 â†’ 100ï¼‰
3. æ£€æŸ¥ Redis Cluster å¥åº·çŠ¶å†µ

### é—®é¢˜ï¼šParser é˜»å¡

**è¯Šæ–­**ï¼š
```bash
# Check if parser is stuck
grep "Parser blocked" log/replicate.log
```

**åŸå› **ï¼šChannel æ»¡ï¼ŒWriter æ— æ³•è·Ÿä¸Šã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. æ£€æŸ¥ Redis å¥åº·çŠ¶å†µï¼ˆæ…¢æŸ¥è¯¢ã€é«˜è´Ÿè½½ï¼‰
2. å¢åŠ  maxConcurrent
3. æ‰©å±• Redis Clusterï¼ˆæ·»åŠ æ›´å¤š Masterï¼‰

## æœ€ä½³å®è·µ

1. **é€‚å½“è°ƒæ•´ç¼“å†²åŒºå¤§å°**ï¼šå¯¹äº 1-10M é”®çš„æ•°æ®é›†ï¼Œ2M æ¡ç›®æ˜¯ä¸€ä¸ªè‰¯å¥½çš„é»˜è®¤å€¼ã€‚

2. **ç›‘æ§ Channel åˆ©ç”¨ç‡**ï¼šå¦‚æœæŒç»­ >80%ï¼Œå¢åŠ ç¼“å†²åŒºæˆ–æé«˜ Writer ååé‡ã€‚

3. **æ ¹æ®æ¨¡å¼è°ƒæ•´æ‰¹æ¬¡å¤§å°**ï¼š
   - é›†ç¾¤æ¨¡å¼ï¼š20Kï¼ˆç”¨äº Slot åˆ†ç»„ï¼‰
   - å•æœºæ¨¡å¼ï¼š2Kï¼ˆç”¨äºæ›´ä½å»¶è¿Ÿï¼‰

4. **è°ƒæ•´åˆ·æ–°é—´éš”**ï¼š
   - å…¨é‡åŒæ­¥ï¼šé•¿é—´éš”ï¼ˆ5000msï¼‰ä»¥æœ€å¤§åŒ–æ‰¹æ¬¡å¤§å°
   - ç¨³å®šåŒæ­¥ï¼šçŸ­é—´éš”ï¼ˆ50msï¼‰ä»¥å®ç°å®æ—¶å¤åˆ¶

5. **ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—**ï¼šåœ¨æ‰€æœ‰æ—¥å¿—æ¶ˆæ¯ä¸­åŒ…å« FLOW-IDã€æ‰¹æ¬¡å¤§å°å’Œæ—¶åºã€‚

## å»¶ä¼¸é˜…è¯»

- [å¤š FLOW æ¶æ„](multi-flow.md)
- [é›†ç¾¤è·¯ç”±ä¼˜åŒ–](cluster-routing.md)
- [æ€§èƒ½è°ƒä¼˜æŒ‡å—](../guides/performance-tuning.md)
