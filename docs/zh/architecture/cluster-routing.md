# Redis Cluster è·¯ç”±ä¼˜åŒ–

æœ¬æ–‡æ¡£è§£é‡Šäº†ä½¿ df2redis åœ¨å†™å…¥ Redis Cluster æ—¶å®ç°é«˜æ€§èƒ½çš„å…³é”®ä¼˜åŒ–ã€‚

## é—®é¢˜ï¼šåŸºäº Slot çš„åˆ†ç»„

### åˆå§‹é”™è¯¯å®ç° âŒ

<img src="../../images/architecture/cluster-routing.svg" alt="é›†ç¾¤è·¯ç”±ç­–ç•¥" width="800" style="max-width: 100%;" />

```go
// âŒ é”™è¯¯ï¼šæŒ‰ Slot åˆ†ç»„
func groupBySlot(entries []*RDBEntry) map[uint16][]*RDBEntry {
    groups := make(map[uint16][]*RDBEntry)

    for _, entry := range entries {
        slot := crc16(entry.Key) % 16384
        groups[slot] = append(groups[slot], entry)
    }

    return groups  // ç»“æœï¼š2000 ä¸ªæ¡ç›®äº§ç”Ÿ ~2000 ä¸ªåˆ†ç»„
}
```

### ä¸ºä»€ä¹ˆè¿™æ ·åšå¾ˆç³Ÿç³•

Redis Cluster æœ‰ **16,384 ä¸ª Slot**ã€‚å¯¹äºåŒ…å« 2000 ä¸ªéšæœºé”®çš„æ‰¹æ¬¡ï¼š

```
2000 ä¸ªé”® / 16384 ä¸ª Slot = å¹³å‡æ¯ä¸ª Slot 0.12 ä¸ªæ¡ç›®

å®é™…åˆ†å¸ƒï¼ˆæ³Šæ¾åˆ†å¸ƒï¼‰ï¼š
- ~1840 ä¸ª Slotï¼š1 ä¸ªæ¡ç›®
- ~150 ä¸ª Slotï¼š2 ä¸ªæ¡ç›®
- ~10 ä¸ª Slotï¼š3+ ä¸ªæ¡ç›®
```

**ç»“æœ**ï¼š~2000 ä¸ªå¾®å‹ Pipelineï¼Œæ¯ä¸ªåªæœ‰ 1-2 ä¸ªå‘½ä»¤ã€‚

### æ€§èƒ½å½±å“

```
åœºæ™¯ï¼šå‘ Redis Cluster å†™å…¥ 2000 ä¸ªé”®

é”™è¯¯å®ç°ï¼ˆåŸºäº Slotï¼‰ï¼š
â”œâ”€ åˆ›å»º ~2000 ä¸ª Slot åˆ†ç»„
â”œâ”€ å‘é€ ~2000 ä¸ª Pipelineï¼ˆæ¯ä¸ª 1 ä¸ªå‘½ä»¤ï¼‰
â”œâ”€ ç½‘ç»œï¼š~2000 RTTs Ã— 100ms = 200 ç§’
â””â”€ ååé‡ï¼š10 ops/sec

æ­£ç¡®å®ç°ï¼ˆåŸºäºèŠ‚ç‚¹ï¼‰ï¼š
â”œâ”€ åˆ›å»º 3 ä¸ªèŠ‚ç‚¹åˆ†ç»„ï¼ˆ3 ä¸ª Masterï¼‰
â”œâ”€ å‘é€ 3 ä¸ª Pipelineï¼ˆæ¯ä¸ª ~666 ä¸ªå‘½ä»¤ï¼‰
â”œâ”€ ç½‘ç»œï¼š3 RTTs Ã— 100ms = 300ms
â””â”€ ååé‡ï¼š6,666 ops/sec

æ€§èƒ½æå‡ï¼š666 å€ï¼ğŸš€
```

## è§£å†³æ–¹æ¡ˆï¼šåŸºäºèŠ‚ç‚¹çš„åˆ†ç»„

### æ­£ç¡®å®ç° âœ…

```go
// âœ… æ­£ç¡®ï¼šæŒ‰ä¸»èŠ‚ç‚¹åˆ†ç»„
func groupByNode(entries []*RDBEntry) map[string][]*RDBEntry {
    groups := make(map[string][]*RDBEntry)

    for _, entry := range entries {
        // æ­¥éª¤ 1ï¼šè®¡ç®— Slot
        slot := crc16(entry.Key) % 16384

        // æ­¥éª¤ 2ï¼šæŸ¥æ‰¾æ­¤ Slot çš„ä¸»èŠ‚ç‚¹ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
        masterAddr := clusterClient.MasterAddrForSlot(slot)

        // æ­¥éª¤ 3ï¼šæŒ‰ä¸»èŠ‚ç‚¹åœ°å€åˆ†ç»„
        groups[masterAddr] = append(groups[masterAddr], entry)
    }

    return groups  // ç»“æœï¼š3 ä¸ªä¸»èŠ‚ç‚¹äº§ç”Ÿ 3 ä¸ªåˆ†ç»„
}
```

### é›†ç¾¤æ‹“æ‰‘æŸ¥æ‰¾

```go
type ClusterTopology struct {
    slotMap map[int]string  // slot â†’ master address
    mu      sync.RWMutex
}

func (c *ClusterClient) MasterAddrForSlot(slot int) string {
    c.mu.RLock()
    defer c.mu.RUnlock()

    return c.topology.slotMap[slot]
}
```

### æ‹“æ‰‘å‘ç°

```go
func (c *ClusterClient) RefreshTopology() error {
    // Execute CLUSTER SLOTS command
    resp, err := c.Do("CLUSTER", "SLOTS")
    if err != nil {
        return err
    }

    // Parse response
    // [[start_slot, end_slot, [master_ip, master_port], [replica_ip, replica_port]], ...]
    slots := parseClusterSlotsResponse(resp)

    c.mu.Lock()
    defer c.mu.Unlock()

    for _, slotRange := range slots {
        startSlot := slotRange.Start
        endSlot := slotRange.End
        masterAddr := slotRange.Master.Addr

        for slot := startSlot; slot <= endSlot; slot++ {
            c.topology.slotMap[slot] = masterAddr
        }
    }

    log.Infof("Cluster topology refreshed: %d masters, %d slots",
        len(c.getMasters()), len(c.topology.slotMap))

    return nil
}
```

## å®ç°ç»†èŠ‚

### å®Œæ•´çš„å†™å…¥ Pipeline

```go
func (fw *FlowWriter) flushBatch(batch []*RDBEntry) {
    // æ­¥éª¤ 1ï¼šæŒ‰ä¸»èŠ‚ç‚¹åˆ†ç»„
    nodeGroups := fw.groupByNode(batch)

    log.Infof("[FLOW-%d] Batch of %d entries â†’ %d node groups",
        fw.flowID, len(batch), len(nodeGroups))

    // æ­¥éª¤ 2ï¼šå¹¶è¡Œå†™å…¥æ¯ä¸ªåˆ†ç»„
    var wg sync.WaitGroup
    for masterAddr, entries := range nodeGroups {
        wg.Add(1)
        go func(addr string, group []*RDBEntry) {
            defer wg.Done()

            fw.writeNodeGroup(addr, group)
        }(masterAddr, entries)
    }

    wg.Wait()
}
```

### å•ä¸ªèŠ‚ç‚¹çš„ Pipeline æ‰§è¡Œ

```go
func (fw *FlowWriter) writeNodeGroup(masterAddr string, entries []*RDBEntry) error {
    // Build pipeline commands
    cmds := make([][]interface{}, 0, len(entries))
    for _, entry := range entries {
        cmd := fw.buildCommand(entry)
        cmds = append(cmds, cmd)
    }

    // Get connection to this master
    conn := fw.clusterClient.GetConnectionForMaster(masterAddr)

    // Execute pipeline
    start := time.Now()
    results, err := conn.Pipeline(cmds)
    duration := time.Since(start)

    if err != nil {
        log.Errorf("[FLOW-%d] Pipeline to %s failed: %v", fw.flowID, masterAddr, err)
        return err
    }

    log.Infof("[FLOW-%d] Wrote %d entries to %s in %v (%.0f ops/sec)",
        fw.flowID, len(entries), masterAddr, duration,
        float64(len(entries))/duration.Seconds())

    return nil
}
```

## å¤„ç†é›†ç¾¤é‡æ–°åˆ†ç‰‡

### MOVED/ASK é‡å®šå‘

åœ¨é›†ç¾¤é‡æ–°åˆ†ç‰‡æœŸé—´ï¼ŒSlot å¯èƒ½åœ¨èŠ‚ç‚¹ä¹‹é—´ç§»åŠ¨ï¼š

```
Client â†’ Node A: SET key value
Node A â†’ Client: -MOVED 12345 10.x.x.x:6379
Client â†’ Node B: SET key value
Node B â†’ Client: OK
```

### è‡ªåŠ¨é‡å®šå‘

```go
func (c *ClusterClient) Do(cmd string, args ...string) (interface{}, error) {
    maxRedirects := 5

    for attempt := 0; attempt < maxRedirects; attempt++ {
        // Calculate slot and route to master
        slot := c.calculateSlot(cmd, args)
        masterAddr := c.MasterAddrForSlot(slot)
        conn := c.GetConnectionForMaster(masterAddr)

        // Execute command
        resp, err := conn.Do(cmd, args...)
        if err == nil {
            return resp, nil
        }

        // Check for MOVED error
        if strings.HasPrefix(err.Error(), "MOVED ") {
            // Parse: "MOVED 12345 10.x.x.x:6379"
            parts := strings.Fields(err.Error())
            newSlot, _ := strconv.Atoi(parts[1])
            newAddr := parts[2]

            // Update topology
            c.mu.Lock()
            c.topology.slotMap[newSlot] = newAddr
            c.mu.Unlock()

            log.Infof("Slot %d moved to %s, retrying", newSlot, newAddr)
            continue  // Retry with new address
        }

        return nil, err
    }

    return nil, fmt.Errorf("max redirects exceeded")
}
```

### ASK é‡å®šå‘ï¼ˆè¿ç§»è¿›è¡Œä¸­ï¼‰

```
Client â†’ Node A: SET key value
Node A â†’ Client: -ASK 12345 10.x.x.x:6379
Client â†’ Node B: ASKING
Client â†’ Node B: SET key value
Node B â†’ Client: OK
```

```go
// Handle ASK error
if strings.HasPrefix(err.Error(), "ASK ") {
    parts := strings.Fields(err.Error())
    askAddr := parts[2]

    askConn := c.GetConnectionForMaster(askAddr)

    // Send ASKING command first
    _, _ = askConn.Do("ASKING")

    // Retry command on ASK target
    return askConn.Do(cmd, args...)
}
```

## æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•è®¾ç½®

- **æº**ï¼šDragonflyï¼Œ500 ä¸‡ä¸ªé”®
- **ç›®æ ‡**ï¼šRedis Clusterï¼Œ3 ä¸ª Master
- **ç½‘ç»œ**ï¼š1 Gbps LANï¼Œ<1ms RTT
- **æ‰¹æ¬¡å¤§å°**ï¼š20,000 æ¡ç›®

### æµ‹è¯•ç»“æœ

| å®ç°æ–¹å¼ | åˆ›å»ºçš„åˆ†ç»„ | å‘é€çš„ Pipeline | æ—¶é—´ | ååé‡ |
|----------------|----------------|----------------|------|------------|
| åŸºäº Slotï¼ˆé”™è¯¯ï¼‰| ~20,000 | ~20,000 | 2000s | 10 ops/sec |
| åŸºäºèŠ‚ç‚¹ï¼ˆæ­£ç¡®ï¼‰| 3 | 3 | 3s | 6,666 ops/sec |

**æ€§èƒ½æå‡ï¼š666 å€**

### å®é™…å½±å“

```
500 ä¸‡ä¸ªé”®çš„å…¨é‡å¤åˆ¶ï¼š

é”™è¯¯å®ç°ï¼š
â”œâ”€ 2500 ä¸ªæ‰¹æ¬¡ï¼ˆæ¯æ‰¹ 2000 æ¡ç›®ï¼‰
â”œâ”€ 2500 Ã— 2000 ä¸ª Pipeline = 500 ä¸‡æ¬¡ç½‘ç»œ RTT
â”œâ”€ 500 ä¸‡ Ã— 100ms = 500,000 ç§’ = 139 å°æ—¶
â””â”€ âŒ æ— æ³•ä½¿ç”¨

æ­£ç¡®å®ç°ï¼š
â”œâ”€ 250 ä¸ªæ‰¹æ¬¡ï¼ˆæ¯æ‰¹ 20,000 æ¡ç›®ï¼‰
â”œâ”€ 250 Ã— 3 ä¸ª Pipeline = 750 æ¬¡ç½‘ç»œ RTT
â”œâ”€ 750 Ã— 100ms = 75 ç§’
â””â”€ âœ… ç”Ÿäº§å°±ç»ª
```

## é…ç½®å»ºè®®

### æ‰¹æ¬¡å¤§å°è°ƒä¼˜

```yaml
# config.yaml

# å¯¹äº Redis Clusterï¼ˆå¿…é¡»å¤§ï¼‰
batchSize: 20000  # ç¡®ä¿å¹³å‡æ¯ä¸ª Slot çº¦ 1.2 ä¸ªæ¡ç›®

# å¯¹äº Redis Standaloneï¼ˆè¾ƒå°ä¹Ÿå¯ä»¥ï¼‰
batchSize: 2000   # æ²¡æœ‰ Slot ç¢ç‰‡åŒ–
```

### å¹¶å‘è°ƒä¼˜

```yaml
# æ¯ä¸ª FLOW çš„æœ€å¤§å¹¶å‘æ‰¹æ¬¡æ•°
maxConcurrentBatches: 50

# å¯¹äºé›†ç¾¤æ¨¡å¼ï¼Œè¿™æ„å‘³ç€ï¼š
# - 50 ä¸ªæ‰¹æ¬¡ Ã— 3 ä¸ªèŠ‚ç‚¹ = 150 ä¸ªå¹¶å‘ Pipeline
```

## æ•…éšœæ’æŸ¥

### ç—‡çŠ¶ï¼šä½ååé‡ (<100 ops/sec)

**æ£€æŸ¥**ï¼š
```bash
grep "node groups" log/replicate.log | head -10
```

**è‰¯å¥½è¾“å‡º**ï¼š
```
[FLOW-0] Batch of 20000 entries â†’ 3 node groups
[FLOW-1] Batch of 20000 entries â†’ 3 node groups
```

**é”™è¯¯è¾“å‡º**ï¼š
```
[FLOW-0] Batch of 2000 entries â†’ 1800 node groups  # âŒ é”™è¯¯ï¼
```

**è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨é…ç½®ä¸­å¢åŠ  `batchSize`ã€‚

### ç—‡çŠ¶ï¼šé¢‘ç¹çš„ MOVED é”™è¯¯

**æ£€æŸ¥**ï¼š
```bash
grep "MOVED" log/replicate.log | wc -l
```

å¦‚æœè®¡æ•° > 1000ï¼Œé›†ç¾¤æ­£åœ¨é¢‘ç¹é‡æ–°åˆ†ç‰‡ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç­‰å¾…é‡æ–°åˆ†ç‰‡å®Œæˆ
2. åœ¨è¿ç§»æœŸé—´ç¦ç”¨è‡ªåŠ¨é‡å¹³è¡¡
3. åœ¨ä»£ç ä¸­å¢åŠ  `maxRedirects`

## å»¶ä¼¸é˜…è¯»

- [å¤š FLOW æ¶æ„](multi-flow.md)
- [æ•°æ®æµæ°´çº¿ä¸èƒŒå‹æ§åˆ¶](data-pipeline.md)
- [æ€§èƒ½è°ƒä¼˜æŒ‡å—](../guides/performance-tuning.md)
