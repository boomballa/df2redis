# å¤š FLOW å¹¶è¡Œæ¶æ„

df2redis å®ç°äº†å®Œå…¨å¹¶è¡Œçš„å¤š FLOW æ¶æ„ï¼Œä¸ Dragonfly çš„åˆ†ç‰‡è®¾è®¡ç›¸åŒ¹é…ï¼Œä»¥å®ç°æœ€å¤§ååé‡ã€‚

## æ¦‚è§ˆ

<!-- ğŸ–¼ï¸ å¤š FLOW æ¶æ„å›¾å ä½ç¬¦ -->
<!-- æ›¿æ¢ä¸ºï¼šdocs/images/architecture/multi-flow.png -->
![å¤š FLOW æ¶æ„](../../images/architecture/multi-flow.png)

```
Dragonfly Master (N ä¸ª Shard)
    â”‚
    â”œâ”€ Shard 0 â”€â”€â”€â”€â–º FLOW-0 â”€â”€â”€â”€â–º Parser-0 â”€â”€â”€â”€â–º Writer-0 â”€â”
    â”œâ”€ Shard 1 â”€â”€â”€â”€â–º FLOW-1 â”€â”€â”€â”€â–º Parser-1 â”€â”€â”€â”€â–º Writer-1 â”€â”¤
    â”œâ”€ Shard 2 â”€â”€â”€â”€â–º FLOW-2 â”€â”€â”€â”€â–º Parser-2 â”€â”€â”€â”€â–º Writer-2 â”€â”¤
    â”œâ”€ Shard 3 â”€â”€â”€â”€â–º FLOW-3 â”€â”€â”€â”€â–º Parser-3 â”€â”€â”€â”€â–º Writer-3 â”€â”¤
    â”œâ”€ Shard 4 â”€â”€â”€â”€â–º FLOW-4 â”€â”€â”€â”€â–º Parser-4 â”€â”€â”€â”€â–º Writer-4 â”€â”¼â”€â–º Redis Cluster
    â”œâ”€ Shard 5 â”€â”€â”€â”€â–º FLOW-5 â”€â”€â”€â”€â–º Parser-5 â”€â”€â”€â”€â–º Writer-5 â”€â”¤
    â”œâ”€ Shard 6 â”€â”€â”€â”€â–º FLOW-6 â”€â”€â”€â”€â–º Parser-6 â”€â”€â”€â”€â–º Writer-6 â”€â”¤
    â””â”€ Shard 7 â”€â”€â”€â”€â–º FLOW-7 â”€â”€â”€â”€â–º Parser-7 â”€â”€â”€â”€â–º Writer-7 â”€â”˜
                         â”‚             â”‚              â”‚
                         â”‚             â”‚              â”‚
                    TCP Stream    RDB Decoder    Batch Writer
                                   Journal         Pipeline
                                   Decoder
```

## è®¾è®¡åŸç†

### ä¸ºä»€ä¹ˆéœ€è¦å¤š FLOWï¼Ÿ

1. **å¹¶è¡Œæ€§**ï¼šDragonfly å°†æ•°æ®åˆ†ç‰‡åˆ°å¤šä¸ªçº¿ç¨‹ã€‚å•è¿æ¥å¤åˆ¶ä¼šé€ æˆç“¶é¢ˆã€‚

2. **é¡ºåºæ€§**ï¼šæ¯ä¸ªåˆ†ç‰‡ç»´æŠ¤è‡ªå·±çš„é¡ºåºä¿è¯ã€‚åœ¨ä¸€ä¸ªæµä¸­æ··åˆå¤šä¸ªåˆ†ç‰‡çš„æ•°æ®ä¼šä½¿ LSN è·Ÿè¸ªå¤æ‚åŒ–ã€‚

3. **æ€§èƒ½**ï¼šå¤šä¸ªå¹¶è¡Œæµå¯ä»¥å……åˆ†åˆ©ç”¨ç½‘ç»œå¸¦å®½å’Œå¤šæ ¸ CPUã€‚

4. **å¯æ‰©å±•æ€§**ï¼šFLOW æ•°é‡éš Dragonfly çš„åˆ†ç‰‡æ•°é‡æ‰©å±•ï¼ˆå¯é…ç½®ï¼Œé€šå¸¸ä¸º Nï¼‰ã€‚

## æ¶æ„å±‚æ¬¡

### å±‚ 1ï¼šFLOW è¿æ¥ç®¡ç†å™¨

**èŒè´£**ï¼šå»ºç«‹å¹¶ç»´æŠ¤åˆ° Dragonfly çš„ TCP è¿æ¥ã€‚

```go
type FLOWConnection struct {
    ID        int
    Conn      net.Conn
    SessionID string
    Reader    *bufio.Reader
}

func (r *Replicator) setupFLOWs(numFlows int) ([]*FLOWConnection, error) {
    flows := make([]*FLOWConnection, numFlows)

    for i := 0; i < numFlows; i++ {
        conn, err := net.Dial("tcp", r.config.Source.Addr)
        if err != nil {
            return nil, fmt.Errorf("FLOW-%d: connection failed: %w", i, err)
        }

        // Set TCP parameters for high throughput
        if tcpConn, ok := conn.(*net.TCPConn); ok {
            tcpConn.SetReadBuffer(10 * 1024 * 1024)  // 10MB
            tcpConn.SetKeepAlive(true)
            tcpConn.SetKeepAlivePeriod(15 * time.Second)
        }

        // Send DFLY FLOW command
        resp, err := redisx.Do(conn, "DFLY", "FLOW", strconv.Itoa(i), "1.0")
        sessionID := parseSessionID(resp)

        flows[i] = &FLOWConnection{
            ID:        i,
            Conn:      conn,
            SessionID: sessionID,
            Reader:    bufio.NewReaderSize(conn, 1024*1024),
        }

        log.Infof("[FLOW-%d] Connected, session: %s", i, sessionID)
    }

    return flows, nil
}
```

### å±‚ 2ï¼šRDB Parserï¼ˆæ¯ä¸ª FLOWï¼‰

**èŒè´£**ï¼šå°† RDB æµè§£ç ä¸ºç»“æ„åŒ–æ¡ç›®ã€‚

```go
func (r *Replicator) parseRDBStream(flowID int, conn *FLOWConnection) error {
    parser := NewRDBParser(conn.Reader)

    for {
        opcode, err := parser.ReadByte()
        if err != nil {
            return fmt.Errorf("[FLOW-%d] read opcode failed: %w", flowID, err)
        }

        if opcode == RDB_OPCODE_FULLSYNC_END {
            log.Infof("[FLOW-%d] RDB phase complete", flowID)
            break
        }

        entry, err := parser.ParseEntry(opcode)
        if err != nil {
            return fmt.Errorf("[FLOW-%d] parse entry failed: %w", flowID, err)
        }

        // Send to writer
        r.writers[flowID].Enqueue(entry)
    }

    return nil
}
```

### å±‚ 3ï¼šWriterï¼ˆæ¯ä¸ª FLOWï¼‰

**èŒè´£**ï¼šæ‰¹é‡ç´¯ç§¯æ¡ç›®å¹¶å†™å…¥ Redisã€‚

```go
type FlowWriter struct {
    flowID      int
    entryChan   chan *RDBEntry
    batchSize   int
    clusterClient *cluster.Client
}

func (fw *FlowWriter) batchWriteLoop() {
    batch := make([]*RDBEntry, 0, fw.batchSize)
    ticker := time.NewTicker(5 * time.Second)

    for {
        select {
        case entry := <-fw.entryChan:
            batch = append(batch, entry)

            if len(batch) >= fw.batchSize {
                fw.flushBatch(batch)
                batch = make([]*RDBEntry, 0, fw.batchSize)
            }

        case <-ticker.C:
            if len(batch) > 0 {
                fw.flushBatch(batch)
                batch = make([]*RDBEntry, 0, fw.batchSize)
            }
        }
    }
}
```

## å…¨å±€åŒæ­¥å±éšœ

### é—®é¢˜

Dragonfly è¦æ±‚æ‰€æœ‰ FLOW åœ¨è¿›å…¥ç¨³å®šåŒæ­¥ä¹‹å‰å®Œæˆ RDB é˜¶æ®µã€‚å¦‚æœ `DFLY STARTSTABLE` å‘é€è¿‡æ—©ï¼š
- æŸäº› FLOW ä»åœ¨æ¥æ”¶ RDB æ•°æ®
- è¿™äº› FLOW ä¼šé”™è¿‡è½¬æ¢æœŸé—´å‘ç”Ÿçš„å†™å…¥
- æ•°æ®ä¸ä¸€è‡´

### è§£å†³æ–¹æ¡ˆï¼šé˜»å¡è®¡æ•°å™¨æ¨¡å¼

çµæ„Ÿæ¥è‡ª Dragonfly çš„ `BlockingCounter` å®ç°ã€‚

```go
// å…¨å±€å±éšœ
rdbCompletionBarrier := make(chan struct{})
var rdbCompleteCount atomic.Int32

// æ¯ä¸ª FLOW goroutine
for i := 0; i < numFlows; i++ {
    go func(flowID int) {
        // Parse RDB stream
        err := r.parseRDBStream(flowID, flows[flowID])
        if err != nil {
            log.Errorf("[FLOW-%d] RDB parsing failed: %v", flowID, err)
            return
        }

        // Read EOF token
        err = r.consumeEOFToken(flows[flowID])
        if err != nil {
            log.Errorf("[FLOW-%d] EOF token failed: %v", flowID, err)
            return
        }

        // Signal completion
        completed := rdbCompleteCount.Add(1)
        log.Infof("[FLOW-%d] RDB phase complete (%d/%d)", flowID, completed, numFlows)

        // Last FLOW closes the barrier
        if completed == int32(numFlows) {
            log.Info("ğŸš§ All FLOWs completed RDB, releasing barrier")
            close(rdbCompletionBarrier)
        }

        // Wait for barrier (synchronize all FLOWs)
        <-rdbCompletionBarrier
        log.Infof("[FLOW-%d] Barrier released, entering stable sync", flowID)

        // Parse journal stream
        r.parseJournalStream(flowID, flows[flowID])
    }(i)
}

// Main goroutine waits for all FLOWs to synchronize
<-rdbCompletionBarrier
log.Info("Sending DFLY STARTSTABLE")
r.masterConn.Do("DFLY", "STARTSTABLE", stableSessionID, "0")
```

### å¯è§†åŒ–

```
Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º

FLOW-0  [RDB Parsing.......] â”¤ Wait â”œ [Journal Stream...]
FLOW-1  [RDB Parsing..........] â”¤ Wt â”œ [Journal Stream...]
FLOW-2  [RDB Parsing.....] â”¤ Wait   â”œ [Journal Stream...]
FLOW-3  [RDB Parsing........] â”¤ Wait â”œ [Journal Stream...]
FLOW-4  [RDB Parsing......] â”¤ Wait  â”œ [Journal Stream...]
FLOW-5  [RDB Parsing...........] â”¤ W â”œ [Journal Stream...]
FLOW-6  [RDB Parsing.........] â”¤ Waiâ”œ [Journal Stream...]
FLOW-7  [RDB Parsing..............] â”œ [Journal Stream...]
                                    â”‚
                                    â””â”€ Barrier releases here
                                       (when FLOW-7 completes)
```

## å¹¶å‘æ§åˆ¶

### Channel ç¼“å†²

æ¯ä¸ª Writer æœ‰ 2M æ¡ç›®çš„ç¼“å†²åŒºæ¥å¸æ”¶çªå‘æµé‡ï¼š

```go
entryChan := make(chan *RDBEntry, 2000000)
```

**å®¹é‡æ¨ç†**ï¼š
- å¹³å‡æ¡ç›®å¤§å°ï¼š~1KB
- ç¼“å†²åŒºå®¹é‡ï¼š2M æ¡ç›® Ã— 1KB = æ¯ä¸ª FLOW 2GB
- æ€»å†…å­˜ï¼šN FLOWs Ã— 2GB = 16GB

### åŸºäºä¿¡å·é‡çš„æ‰¹æ¬¡é™åˆ¶

é˜²æ­¢è¿‡å¤šå¹¶å‘å†™æ“ä½œï¼š

```go
type FlowWriter struct {
    writeSemaphore chan struct{}  // Max concurrent batches
}

func NewFlowWriter(maxConcurrent int) *FlowWriter {
    return &FlowWriter{
        writeSemaphore: make(chan struct{}, maxConcurrent),
    }
}

func (fw *FlowWriter) flushBatch(batch []*RDBEntry) {
    // Acquire semaphore slot
    fw.writeSemaphore <- struct{}{}

    go func() {
        defer func() { <-fw.writeSemaphore }()  // Release slot

        // Write batch to Redis
        fw.writeBatchToRedis(batch)
    }()
}
```

## æ€§èƒ½ç‰¹æ€§

### ååé‡

**å…¨é‡åŒæ­¥ï¼ˆRDB é˜¶æ®µï¼‰**ï¼š
- å•ä¸ª FLOWï¼š~12,000 ops/sec
- æ€»è®¡ï¼ˆN FLOWsï¼‰ï¼š~96,000 ops/sec

**ç¨³å®šåŒæ­¥ï¼ˆJournal é˜¶æ®µï¼‰**ï¼š
- å•ä¸ª FLOWï¼š~5,000 ops/secï¼ˆå—æºå†™å…¥é€Ÿç‡é™åˆ¶ï¼‰
- æ€»è®¡ï¼ˆN FLOWsï¼‰ï¼š~40,000 ops/sec

### å»¶è¿Ÿ

- **RDB è§£æ**ï¼šæ¯ä¸ªæ¡ç›® <0.1ms
- **æ‰¹æ¬¡ç´¯ç§¯**ï¼š5000msï¼ˆå¯é…ç½®ï¼Œé›†ç¾¤æ¨¡å¼ï¼‰
- **Redis å†™å…¥ï¼ˆPipelineï¼‰**ï¼šæ¯æ‰¹ï¼ˆ500 æ¡ç›®ï¼‰5-20ms
- **ç«¯åˆ°ç«¯**ï¼šä» Dragonfly å†™å…¥åˆ° Redis ç¡®è®¤ <50ms

### èµ„æºä½¿ç”¨

| èµ„æº | å•ä¸ª FLOW | æ€»è®¡ï¼ˆN FLOWsï¼‰|
|----------|----------|--------------------|
| å†…å­˜ | 2GB | 16GB |
| CPU | ~50% | ~400% |
| ç½‘ç»œ | 10-50 MB/s | 80-400 MB/s |
| Goroutines | 2ï¼ˆparser + writerï¼‰| 16 |

## æ•…éšœå¤„ç†

### FLOW çº§åˆ«æ•…éšœ

å¦‚æœå•ä¸ª FLOW å¤±è´¥ï¼š
- è®°å½•é”™è¯¯å¹¶æ ‡è®° FLOW ä¸ºå¤±è´¥
- ç»§ç»­å¤„ç†å…¶ä»– FLOW
- ä»…å½“è¶…è¿‡å…³é”®é˜ˆå€¼ï¼ˆä¾‹å¦‚ >25% å¤±è´¥ï¼‰æ—¶æ•´ä¸ªå¤åˆ¶æ‰å¤±è´¥

```go
var failedFlows atomic.Int32

go func(flowID int) {
    if err := r.parseRDBStream(flowID, flows[flowID]); err != nil {
        log.Errorf("[FLOW-%d] Failed: %v", flowID, err)
        failedFlows.Add(1)

        if failedFlows.Load() > int32(numFlows/4) {
            log.Fatal("Too many FLOWs failed, aborting replication")
        }
        return
    }
}(i)
```

### ç½‘ç»œä¸­æ–­

- TCP keepaliveï¼ˆ15 ç§’ï¼‰æ£€æµ‹æ­»è¿æ¥
- ä½¿ç”¨æŒ‡æ•°é€€é¿çš„è‡ªåŠ¨é‡è¿
- ä»ä¸Šæ¬¡ Checkpoint LSN æ¢å¤

### å±éšœæ­»é”é¢„é˜²

å¦‚æœä¸€ä¸ª FLOW æŒ‚èµ·ï¼Œå±éšœæ°¸è¿œä¸ä¼šå…³é—­ã€‚é¢„é˜²æªæ–½ï¼š

```go
// åŸºäºè¶…æ—¶çš„å±éšœ
select {
case <-rdbCompletionBarrier:
    log.Info("All FLOWs completed normally")
case <-time.After(10 * time.Minute):
    log.Fatal("RDB phase timeout (10m), some FLOWs may be stuck")
}
```

## ç›‘æ§

### å•ä¸ª FLOW æŒ‡æ ‡

```go
type FLOWStats struct {
    TotalEntries  int64
    TotalBytes    int64
    ErrorCount    int64
    LastActivityTime time.Time
}

// Export to Prometheus
flowEntriesTotal.WithLabelValues(strconv.Itoa(flowID)).Add(float64(count))
flowBytesTotal.WithLabelValues(strconv.Itoa(flowID)).Add(float64(bytes))
```

### å¥åº·æ£€æŸ¥

æ£€æµ‹å¡ä½çš„ FLOWï¼š

```go
func (r *Replicator) monitorFLOWHealth() {
    ticker := time.NewTicker(30 * time.Second)
    for range ticker.C {
        for i, stats := range r.flowStats {
            if time.Since(stats.LastActivityTime) > 60*time.Second {
                log.Warnf("[FLOW-%d] No activity for 60s, may be stuck", i)
            }
        }
    }
}
```

## æœ€ä½³å®è·µ

1. **åŒ¹é… Dragonfly çš„åˆ†ç‰‡æ•°é‡**ï¼šä½¿ç”¨ä¸ Dragonfly åˆ†ç‰‡ç›¸åŒæ•°é‡çš„ FLOWã€‚
2. **é€‚å½“è°ƒæ•´ç¼“å†²åŒºå¤§å°**ï¼šå¯¹äº 1-10M é”®çš„æ•°æ®é›†ï¼Œæ¯ä¸ª FLOW 2M æ¡ç›®æ˜¯ä¸€ä¸ªè‰¯å¥½çš„å¹³è¡¡ã€‚
3. **ç›‘æ§å±éšœæ—¶é—´**ï¼šå¦‚æœå±éšœæŒç»­ >5 åˆ†é’Ÿï¼Œè°ƒæŸ¥æ…¢é€Ÿ FLOWã€‚
4. **ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—**ï¼šåœ¨æ‰€æœ‰æ—¥å¿—æ¶ˆæ¯ä¸­åŒ…å« FLOW-IDï¼Œä¾¿äºè°ƒè¯•ã€‚

## å»¶ä¼¸é˜…è¯»

- [å¤åˆ¶åè®®æ·±åº¦è§£æ](replication-protocol.md)
- [æ•°æ®æµæ°´çº¿ä¸èƒŒå‹æ§åˆ¶](data-pipeline.md)
- [æ€§èƒ½è°ƒä¼˜æŒ‡å—](../guides/performance-tuning.md)
