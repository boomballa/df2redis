package replica

import (
	"context"
	"fmt"
	"io"
	"log"
	"strconv"
	"strings"
	"sync"
	"time"

	"df2redis/internal/checkpoint"
	"df2redis/internal/cluster"
	"df2redis/internal/config"
	"df2redis/internal/redisx"
)

// Replicator establishes the replication relationship with Dragonfly
type Replicator struct {
	cfg    *config.Config
	ctx    context.Context
	cancel context.CancelFunc

	// Primary connection (used for handshake)
	mainConn *redisx.Client

	// Dedicated connections for each FLOW
	flowConns []*redisx.Client

	// Redis Cluster client (replay commands)
	clusterClient *cluster.ClusterClient

	// Checkpoint manager
	checkpointMgr *checkpoint.Manager

	// Replication state
	state      ReplicaState
	masterInfo MasterInfo
	flows      []FlowInfo

	// Configuration
	listeningPort int
	announceIP    string

	// Replay statistics
	replayStats ReplayStats

	// Automatic checkpoint saving
	checkpointInterval time.Duration
	lastCheckpointTime time.Time

	// Channel used to wait for Start() to finish
	done chan struct{}
}

// NewReplicator creates a new replicator
func NewReplicator(cfg *config.Config) *Replicator {
	ctx, cancel := context.WithCancel(context.Background())

	// Checkpoint file path: use configured path or the default path
	checkpointPath := cfg.ResolveCheckpointPath()

	// Checkpoint save interval: read from config (default 10 seconds)
	checkpointInterval := time.Duration(cfg.Checkpoint.Interval) * time.Second

	return &Replicator{
		cfg:                cfg,
		ctx:                ctx,
		cancel:             cancel,
		state:              StateDisconnected,
		listeningPort:      6380, // default port
		checkpointMgr:      checkpoint.NewManager(checkpointPath),
		checkpointInterval: checkpointInterval,
		done:               make(chan struct{}),
	}
}

// Start launches the replication workflow
func (r *Replicator) Start() error {
	defer close(r.done) // ensure Stop() gets notified when exiting

	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	log.Println("ğŸš€ å¯åŠ¨ Dragonfly å¤åˆ¶å™¨")
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// Connect to Dragonfly
	if err := r.connect(); err != nil {
		return fmt.Errorf("è¿æ¥å¤±è´¥: %w", err)
	}

	// Perform handshake
	if err := r.handshake(); err != nil {
		return fmt.Errorf("æ¡æ‰‹å¤±è´¥: %w", err)
	}

	// Initialize Redis client (auto-detects cluster/standalone)
	log.Println("")
	log.Println("ğŸ”— è¿æ¥åˆ°ç›®æ ‡ Redis...")
	r.clusterClient = cluster.NewClusterClient(
		r.cfg.Target.Seed,
		r.cfg.Target.Password,
		r.cfg.Target.TLS,
	)
	if err := r.clusterClient.Connect(); err != nil {
		return fmt.Errorf("è¿æ¥ç›®æ ‡ Redis å¤±è´¥: %w", err)
	}

	// Detect topology
	topology := r.clusterClient.GetTopology()
	if len(topology) > 0 {
		log.Printf("  âœ“ Redis Cluster è¿æ¥æˆåŠŸï¼ˆ%d ä¸ªä¸»èŠ‚ç‚¹ï¼‰", len(topology))
	} else {
		log.Println("  âœ“ Redis Standalone è¿æ¥æˆåŠŸ")
	}

	// Send DFLY SYNC to trigger the RDB transfer
	if err := r.sendDflySync(); err != nil {
		return fmt.Errorf("å‘é€ DFLY SYNC å¤±è´¥: %w", err)
	}

	// Receive snapshot in parallel
	r.state = StateFullSync
	if err := r.receiveSnapshot(); err != nil {
		return fmt.Errorf("æ¥æ”¶å¿«ç…§å¤±è´¥: %w", err)
	}

	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	log.Println("ğŸ¯ å¤åˆ¶å™¨å¯åŠ¨æˆåŠŸï¼")
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// Receive and parse the journal stream
	if err := r.receiveJournal(); err != nil {
		return fmt.Errorf("æ¥æ”¶ Journal æµå¤±è´¥: %w", err)
	}

	return nil
}

// Stop halts replication
func (r *Replicator) Stop() {
	log.Println("â¸  åœæ­¢å¤åˆ¶å™¨...")

	// Cancel the context first
	r.cancel()

	// Close all connections immediately so blocking reads fail fast
	if r.mainConn != nil {
		r.mainConn.Close()
	}
	for i, conn := range r.flowConns {
		if conn != nil {
			log.Printf("  â€¢ å…³é—­ FLOW-%d è¿æ¥", i)
			conn.Close()
		}
	}

	// Wait for Start() to finish (including checkpoint persistence)
	log.Println("  â€¢ ç­‰å¾…æ‰€æœ‰ goroutine é€€å‡º...")
	<-r.done

	r.state = StateStopped
	log.Println("âœ“ å¤åˆ¶å™¨å·²åœæ­¢")
}

// connect creates the primary connection to Dragonfly for the handshake
func (r *Replicator) connect() error {
	r.state = StateConnecting
	log.Printf("ğŸ”— è¿æ¥åˆ° Dragonfly: %s", r.cfg.Source.Addr)

	dialCtx, cancel := context.WithTimeout(r.ctx, 10*time.Second)
	defer cancel()

	client, err := redisx.Dial(dialCtx, redisx.Config{
		Addr:     r.cfg.Source.Addr,
		Password: r.cfg.Source.Password,
		TLS:      r.cfg.Source.TLS,
	})

	if err != nil {
		return fmt.Errorf("æ— æ³•è¿æ¥åˆ° %s: %w", r.cfg.Source.Addr, err)
	}

	r.mainConn = client
	log.Printf("âœ“ ä¸»è¿æ¥å»ºç«‹æˆåŠŸ")

	return nil
}

// handshake performs the full handshake procedure
func (r *Replicator) handshake() error {
	r.state = StateHandshaking
	log.Println("")
	log.Println("ğŸ¤ å¼€å§‹æ¡æ‰‹æµç¨‹")
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	// Step 1: PING
	log.Println("  [1/6] å‘é€ PING...")
	if err := r.sendPing(); err != nil {
		return err
	}
	log.Println("  âœ“ PONG æ”¶åˆ°")

	// Step 2: REPLCONF listening-port
	log.Printf("  [2/6] å£°æ˜ç›‘å¬ç«¯å£: %d...", r.listeningPort)
	if err := r.sendListeningPort(); err != nil {
		return err
	}
	log.Println("  âœ“ ç«¯å£å·²æ³¨å†Œ")

	// Step 3: REPLCONF ip-address (optional)
	if r.announceIP != "" {
		log.Printf("  [3/6] å£°æ˜ IP åœ°å€: %s...", r.announceIP)
		if err := r.sendIPAddress(); err != nil {
			log.Printf("  âš  IP åœ°å€æ³¨å†Œå¤±è´¥ï¼ˆä¸»åº“å¯èƒ½æ˜¯æ—§ç‰ˆæœ¬ï¼‰: %v", err)
		} else {
			log.Println("  âœ“ IP åœ°å€å·²æ³¨å†Œ")
		}
	} else {
		log.Println("  [3/6] è·³è¿‡ IP åœ°å€å£°æ˜")
	}

	// Step 4: REPLCONF capa eof psync2
	log.Println("  [4/6] å£°æ˜èƒ½åŠ›: eof psync2...")
	if err := r.sendCapaEOF(); err != nil {
		return err
	}
	log.Println("  âœ“ èƒ½åŠ›å·²å£°æ˜")

	// Step 5: REPLCONF capa dragonfly
	log.Println("  [5/6] å£°æ˜ Dragonfly å…¼å®¹æ€§...")
	if err := r.sendCapaDragonfly(); err != nil {
		return err
	}
	log.Printf("  âœ“ Dragonfly ç‰ˆæœ¬: %s, Shard æ•°é‡: %d", r.masterInfo.Version, r.masterInfo.NumFlows)

	// Step 6: establish FLOW connections
	log.Printf("  [6/6] å»ºç«‹ %d ä¸ª FLOW...", r.masterInfo.NumFlows)
	if err := r.establishFlows(); err != nil {
		return err
	}
	log.Printf("  âœ“ æ‰€æœ‰ FLOW å·²å»ºç«‹")

	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	log.Println("âœ“ æ¡æ‰‹å®Œæˆ")
	log.Println("")

	r.state = StatePreparation
	return nil
}

// sendPing issues a PING command over the main connection
func (r *Replicator) sendPing() error {
	resp, err := r.mainConn.Do("PING")
	if err != nil {
		return fmt.Errorf("PING å¤±è´¥: %w", err)
	}

	reply, err := redisx.ToString(resp)
	if err != nil || reply != "PONG" {
		return fmt.Errorf("æœŸæœ› PONGï¼Œä½†æ”¶åˆ°: %v", resp)
	}

	return nil
}

// sendListeningPort sends REPLCONF listening-port
func (r *Replicator) sendListeningPort() error {
	resp, err := r.mainConn.Do("REPLCONF", "listening-port", strconv.Itoa(r.listeningPort))
	if err != nil {
		return fmt.Errorf("REPLCONF listening-port å¤±è´¥: %w", err)
	}

	return r.expectOK(resp)
}

// sendIPAddress sends REPLCONF ip-address
func (r *Replicator) sendIPAddress() error {
	resp, err := r.mainConn.Do("REPLCONF", "ip-address", r.announceIP)
	if err != nil {
		return fmt.Errorf("REPLCONF ip-address å¤±è´¥: %w", err)
	}

	return r.expectOK(resp)
}

// sendCapaEOF sends REPLCONF capa eof/capa psync2
func (r *Replicator) sendCapaEOF() error {
	resp, err := r.mainConn.Do("REPLCONF", "capa", "eof", "capa", "psync2")
	if err != nil {
		return fmt.Errorf("REPLCONF capa eof psync2 å¤±è´¥: %w", err)
	}

	return r.expectOK(resp)
}

// sendCapaDragonfly sends REPLCONF capa dragonfly and parses the response
func (r *Replicator) sendCapaDragonfly() error {
	resp, err := r.mainConn.Do("REPLCONF", "capa", "dragonfly")
	if err != nil {
		return fmt.Errorf("REPLCONF capa dragonfly å¤±è´¥: %w", err)
	}

	// Parse response
	// Dragonfly response format (v1.30.0):
	// Array: [replication_id, sync_version, unknown_param, num_flows]
	// Example: ["16c2763d...", "SYNC5", 8, 4]

	arr, err := redisx.ToStringSlice(resp)
	if err != nil {
		// Not an array, try parsing as a simple string
		if str, err2 := redisx.ToString(resp); err2 == nil {
			// Check if it is OK (older versions or vanilla Redis)
			if str == "OK" {
				return fmt.Errorf("ç›®æ ‡æ˜¯ Redis æˆ–æ—§ç‰ˆæœ¬ Dragonflyï¼ˆæ”¶åˆ°ç®€å• OK å“åº”ï¼‰")
			}
			return fmt.Errorf("ç›®æ ‡ä¸æ˜¯ Dragonflyï¼ˆæ”¶åˆ°æœªçŸ¥å“åº”: %sï¼‰", str)
		}
		return fmt.Errorf("æ— æ³•è§£æ capa dragonfly å“åº”: %w", err)
	}

	// Validate length
	if len(arr) < 4 {
		return fmt.Errorf("Dragonfly å“åº”æ ¼å¼é”™è¯¯ï¼ˆé•¿åº¦ä¸è¶³ï¼ŒæœŸæœ› 4 ä¸ªå…ƒç´ ï¼‰: %v", arr)
	}

	// Response layout: [master_id, sync_id, flow_count, version]
	// e.g. ["16c2763d...", "SYNC11", 8, 4]

	// Element 0: replication ID (master_id)
	r.masterInfo.ReplID = arr[0]

	// Element 1: sync session ID (e.g. "SYNC11")
	r.masterInfo.SyncID = arr[1]

	// Element 2: number of flows
	numFlows, err := strconv.Atoi(arr[2])
	if err != nil {
		return fmt.Errorf("æ— æ³•è§£æ flow æ•°é‡: %s", arr[2])
	}
	r.masterInfo.NumFlows = numFlows

	// Element 3: Dragonfly protocol version
	version, err := strconv.Atoi(arr[3])
	if err != nil {
		return fmt.Errorf("æ— æ³•è§£æåè®®ç‰ˆæœ¬: %s", arr[3])
	}
	r.masterInfo.Version = DflyVersion(version)

	log.Printf("  â†’ å¤åˆ¶ ID: %s", r.masterInfo.ReplID[:8]+"...")
	log.Printf("  â†’ åŒæ­¥ä¼šè¯: %s", r.masterInfo.SyncID)
	log.Printf("  â†’ Flow æ•°é‡: %d", r.masterInfo.NumFlows)
	log.Printf("  â†’ åè®®ç‰ˆæœ¬: %s", r.masterInfo.Version)

	return nil
}

// establishFlows creates dedicated FLOW connections for each shard
func (r *Replicator) establishFlows() error {
	numFlows := r.masterInfo.NumFlows
	log.Printf("    â€¢ å°†å»ºç«‹ %d ä¸ªå¹¶è¡Œ FLOW è¿æ¥...", numFlows)

	r.flows = make([]FlowInfo, numFlows)
	r.flowConns = make([]*redisx.Client, numFlows)

	// Create independent TCP connections for each FLOW
	for i := 0; i < numFlows; i++ {
		log.Printf("    â€¢ å»ºç«‹ FLOW-%d ç‹¬ç«‹è¿æ¥...", i)

		// 1. Create a new TCP connection
		dialCtx, cancel := context.WithTimeout(r.ctx, 10*time.Second)
		flowConn, err := redisx.Dial(dialCtx, redisx.Config{
			Addr:     r.cfg.Source.Addr,
			Password: r.cfg.Source.Password,
			TLS:      r.cfg.Source.TLS,
		})
		cancel()

		if err != nil {
			return fmt.Errorf("FLOW-%d è¿æ¥å¤±è´¥: %w", i, err)
		}

		r.flowConns[i] = flowConn

		// 2. Send PING (optional, ensures the connection is alive)
		if err := flowConn.Ping(); err != nil {
			return fmt.Errorf("FLOW-%d PING å¤±è´¥: %w", i, err)
		}

		// 3. Send DFLY FLOW to register this FLOW
		// Command: DFLY FLOW <master_id> <sync_id> <flow_id>
		resp, err := flowConn.Do("DFLY", "FLOW", r.masterInfo.ReplID, r.masterInfo.SyncID, strconv.Itoa(i))
		if err != nil {
			return fmt.Errorf("FLOW-%d æ³¨å†Œå¤±è´¥: %w", i, err)
		}

		// 4. Parse response: ["FULL", <eof_token>] or ["PARTIAL", <eof_token>]
		arr, err := redisx.ToStringSlice(resp)
		if err != nil {
			// Could be a simple OK string
			if err := r.expectOK(resp); err != nil {
				return fmt.Errorf("FLOW-%d è¿”å›é”™è¯¯: %w", i, err)
			}
			r.flows[i] = FlowInfo{
				FlowID:   i,
				State:    "established",
				SyncType: "OK",
				EOFToken: "",
			}
		} else {
			if len(arr) < 2 {
				return fmt.Errorf("FLOW-%d å“åº”æ ¼å¼é”™è¯¯ï¼ŒæœŸæœ› 2 ä¸ªå…ƒç´ : %v", i, arr)
			}
			syncType := arr[0]
			eofToken := arr[1]

			r.flows[i] = FlowInfo{
				FlowID:   i,
				State:    "established",
				SyncType: syncType,
				EOFToken: eofToken,
			}

			log.Printf("      â†’ åŒæ­¥ç±»å‹: %s, EOF Token: %s...", syncType, eofToken[:min(8, len(eofToken))])
		}

		log.Printf("    âœ“ FLOW-%d è¿æ¥å’Œæ³¨å†Œå®Œæˆ", i)
	}

	log.Printf("    âœ“ æ‰€æœ‰ %d ä¸ª FLOW è¿æ¥å·²å»ºç«‹", numFlows)
	return nil
}

// min returns the smaller of two integers
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// sendDflySync issues DFLY SYNC to trigger the RDB transfer.
// Must be called only after every FLOW is established, otherwise Dragonfly will not send data.
func (r *Replicator) sendDflySync() error {
	log.Println("")
	log.Println("ğŸ”„ å‘é€ DFLY SYNC è§¦å‘æ•°æ®ä¼ è¾“...")

	// Send DFLY SYNC via the main connection
	// Command: DFLY SYNC <sync_id>
	resp, err := r.mainConn.Do("DFLY", "SYNC", r.masterInfo.SyncID)
	if err != nil {
		return fmt.Errorf("DFLY SYNC å¤±è´¥: %w", err)
	}

	// Expect OK
	if err := r.expectOK(resp); err != nil {
		return fmt.Errorf("DFLY SYNC è¿”å›é”™è¯¯: %w", err)
	}

	log.Println("  âœ“ DFLY SYNC å‘é€æˆåŠŸï¼ŒRDB æ•°æ®ä¼ è¾“å·²è§¦å‘")
	return nil
}

// expectOK validates that a Redis reply is the literal OK
func (r *Replicator) expectOK(resp interface{}) error {
	reply, err := redisx.ToString(resp)
	if err != nil {
		return fmt.Errorf("æœŸæœ› OKï¼Œä½†æ”¶åˆ°éå­—ç¬¦ä¸²å“åº”: %v", resp)
	}

	if reply != "OK" {
		return fmt.Errorf("æœŸæœ› OKï¼Œä½†æ”¶åˆ°: %s", reply)
	}

	return nil
}

// receiveSnapshot concurrently receives and parses RDB snapshots from all FLOW connections.
// Flow: use the RDB parser to decode data and write it into the target Redis.
// EOF tokens are validated after STARTSTABLE is issued.
func (r *Replicator) receiveSnapshot() error {
	log.Println("")
	log.Println("ğŸ“¦ å¼€å§‹å¹¶è¡Œæ¥æ”¶å’Œè§£æ RDB å¿«ç…§...")
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	numFlows := len(r.flows)
	if numFlows == 0 {
		return fmt.Errorf("æ²¡æœ‰å¯ç”¨çš„ FLOW")
	}

	log.Printf("  â€¢ å°†ä½¿ç”¨ %d ä¸ª FLOW å¹¶è¡Œæ¥æ”¶å’Œè§£æ RDB å¿«ç…§", numFlows)

	// Wait for all goroutines
	var wg sync.WaitGroup
	errChan := make(chan error, numFlows)

	// Stats
	type FlowStats struct {
		KeyCount     int
		SkippedCount int
		ErrorCount   int
	}
	statsMap := make(map[int]*FlowStats)
	var statsMu sync.Mutex

	// Start a goroutine per FLOW to read and parse RDB data
	for i := 0; i < numFlows; i++ {
		statsMap[i] = &FlowStats{}
		wg.Add(1)
		go func(flowID int) {
			defer wg.Done()

			flowConn := r.flowConns[flowID]
			stats := statsMap[flowID]

			log.Printf("  [FLOW-%d] å¼€å§‹è§£æ RDB æ•°æ®...", flowID)

			// Create RDB parser
			parser := NewRDBParser(flowConn, flowID)

			// 1. Parse header
			if err := parser.ParseHeader(); err != nil {
				errChan <- fmt.Errorf("FLOW-%d: è§£æ RDB å¤´éƒ¨å¤±è´¥: %w", flowID, err)
				return
			}
			log.Printf("  [FLOW-%d] âœ“ RDB å¤´éƒ¨è§£ææˆåŠŸ", flowID)

			// 2. Parse entries
			for {
				// Observe cancellation
				select {
				case <-r.ctx.Done():
					errChan <- fmt.Errorf("FLOW-%d: å¿«ç…§æ¥æ”¶è¢«å–æ¶ˆ", flowID)
					return
				default:
				}

				// Parse next entry
				entry, err := parser.ParseNext()
				if err != nil {
					if err == io.EOF {
						log.Printf("  [FLOW-%d] âœ“ RDB è§£æå®Œæˆï¼ˆæˆåŠŸ=%d, è·³è¿‡=%d, å¤±è´¥=%dï¼‰",
							flowID, stats.KeyCount, stats.SkippedCount, stats.ErrorCount)
						// FULLSYNC_END received, snapshot done.
						// EOF tokens are read after STARTSTABLE.
						return
					}
					errChan <- fmt.Errorf("FLOW-%d: è§£æå¤±è´¥: %w", flowID, err)
					return
				}

				// Skip expired keys
				if entry.IsExpired() {
					statsMu.Lock()
					stats.SkippedCount++
					statsMu.Unlock()
					continue
				}

				// Write entry into Redis
				if err := r.writeRDBEntry(entry); err != nil {
					log.Printf("  [FLOW-%d] âš  å†™å…¥å¤±è´¥ (key=%s): %v", flowID, entry.Key, err)
					statsMu.Lock()
					stats.ErrorCount++
					statsMu.Unlock()
				} else {
					statsMu.Lock()
					stats.KeyCount++
					statsMu.Unlock()

					// Log progress every 100 keys
					if stats.KeyCount%100 == 0 {
						log.Printf("  [FLOW-%d] â€¢ å·²å¯¼å…¥: %d ä¸ªé”®", flowID, stats.KeyCount)
					}
				}
			}
		}(i)
	}

	// Wait for goroutines
	wg.Wait()
	close(errChan)

	// Drain errors
	for err := range errChan {
		if err != nil {
			return err
		}
	}

	// Final stats
	totalKeys := 0
	totalSkipped := 0
	totalErrors := 0
	for flowID, stats := range statsMap {
		totalKeys += stats.KeyCount
		totalSkipped += stats.SkippedCount
		totalErrors += stats.ErrorCount
	log.Printf("  [FLOW-%d] ç»Ÿè®¡: æˆåŠŸ=%d, è·³è¿‡=%d, å¤±è´¥=%d",
		flowID, stats.KeyCount, stats.SkippedCount, stats.ErrorCount)
	}

	log.Printf("  âœ“ RDB å…¨é‡å¯¼å…¥å®Œæˆ: æ€»è®¡ %d ä¸ªé”®, è·³è¿‡ %d ä¸ªï¼ˆå·²è¿‡æœŸï¼‰, å¤±è´¥ %d ä¸ª",
		totalKeys, totalSkipped, totalErrors)

	// Dragonfly only sends EOF tokens after STARTSTABLE; reading before that causes a 60s timeout.
	if err := r.sendStartStable(); err != nil {
		return fmt.Errorf("åˆ‡æ¢ç¨³å®šåŒæ­¥å¤±è´¥: %w", err)
	}

	if err := r.verifyEofTokens(); err != nil {
		return fmt.Errorf("éªŒè¯ EOF Token å¤±è´¥: %w", err)
	}
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	return nil
}

// sendStartStable issues DFLY STARTSTABLE on the main connection
func (r *Replicator) sendStartStable() error {
	log.Println("")
	log.Println("ğŸ”„ åˆ‡æ¢åˆ°ç¨³å®šåŒæ­¥æ¨¡å¼...")

	resp, err := r.mainConn.Do("DFLY", "STARTSTABLE", r.masterInfo.SyncID)
	if err != nil {
		return fmt.Errorf("DFLY STARTSTABLE å¤±è´¥: %w", err)
	}

	if err := r.expectOK(resp); err != nil {
		return fmt.Errorf("DFLY STARTSTABLE è¿”å›é”™è¯¯: %w", err)
	}

	log.Println("  âœ“ å·²åˆ‡æ¢åˆ°ç¨³å®šåŒæ­¥æ¨¡å¼")
	r.state = StateStableSync
	return nil
}

// verifyEofTokens validates EOF tokens emitted by each FLOW after STARTSTABLE.
// After STARTSTABLE each FLOW sends:
//   1. EOF opcode (0xFF) - 1 byte
//   2. Checksum - 8 bytes
//   3. EOF token - 40 bytes
func (r *Replicator) verifyEofTokens() error {
	log.Println("")
	log.Println("ğŸ” éªŒè¯ EOF Token...")
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	numFlows := len(r.flowConns)
	var wg sync.WaitGroup
	errChan := make(chan error, numFlows)

	for i := 0; i < numFlows; i++ {
		wg.Add(1)
		go func(flowID int) {
			defer wg.Done()
			flowConn := r.flowConns[flowID]
			expectedToken := r.flows[flowID].EOFToken
			tokenLen := len(expectedToken)
			if tokenLen == 0 {
				errChan <- fmt.Errorf("FLOW-%d: æœªè·å–åˆ° EOF Token", flowID)
				return
			}
			log.Printf("  [FLOW-%d] â†’ æ­£åœ¨è¯»å– EOF Token (%d å­—èŠ‚)...", flowID, tokenLen)

			// 1. Skip metadata block (0xD3 + 8 bytes). Dragonfly sends it before EOF.
			metadataBuf := make([]byte, 9) // 1 byte opcode + 8 bytes data
			if _, err := io.ReadFull(flowConn, metadataBuf); err != nil {
				errChan <- fmt.Errorf("FLOW-%d: è¯»å–å…ƒæ•°æ®å¤±è´¥: %w", flowID, err)
				return
			}

			// 2. Read EOF opcode (0xFF)
			opcodeBuf := make([]byte, 1)
			if _, err := io.ReadFull(flowConn, opcodeBuf); err != nil {
				errChan <- fmt.Errorf("FLOW-%d: è¯»å– EOF opcode å¤±è´¥: %w", flowID, err)
				return
			}
			if opcodeBuf[0] != 0xFF {
				errChan <- fmt.Errorf("FLOW-%d: æœŸæœ› EOF opcode 0xFFï¼Œå®é™…æ”¶åˆ° 0x%02X", flowID, opcodeBuf[0])
				return
			}

			// 3. Read checksum (8 bytes)
			checksumBuf := make([]byte, 8)
			if _, err := io.ReadFull(flowConn, checksumBuf); err != nil {
				errChan <- fmt.Errorf("FLOW-%d: è¯»å– checksum å¤±è´¥: %w", flowID, err)
				return
			}

			// 4. Read EOF token (40 bytes)
			tokenBuf := make([]byte, 40)
			if _, err := io.ReadFull(flowConn, tokenBuf); err != nil {
				errChan <- fmt.Errorf("FLOW-%d: è¯»å– EOF token å¤±è´¥: %w", flowID, err)
				return
			}
			receivedToken := string(tokenBuf)

			// 5. Compare token
			if receivedToken != expectedToken {
				errChan <- fmt.Errorf("FLOW-%d: EOF token ä¸åŒ¹é…\n  æœŸæœ›: %s\n  å®é™…: %s",
					flowID, expectedToken, receivedToken)
				return
			}

			log.Printf("  [FLOW-%d] âœ“ EOF Token éªŒè¯æˆåŠŸ", flowID)
		}(i)
	}

	wg.Wait()
	close(errChan)

	// Surface the first error if any
	for err := range errChan {
		return err
	}

	log.Println("  âœ“ æ‰€æœ‰ FLOW çš„ EOF Token éªŒè¯å®Œæˆ")
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
	return nil
}

// FlowEntry represents a journal entry tagged with its FLOW ID
type FlowEntry struct {
	FlowID int
	Entry  *JournalEntry
	Error  error
}

// receiveJournal consumes journal streams from all FLOW connections in parallel
func (r *Replicator) receiveJournal() error {
	log.Println("")
	log.Println("ğŸ“¡ å¼€å§‹æ¥æ”¶ Journal æµ...")
	log.Println("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

	numFlows := len(r.flowConns)
	if numFlows == 0 {
		return fmt.Errorf("æ²¡æœ‰å¯ç”¨çš„ FLOW è¿æ¥")
	}

	log.Printf("  â€¢ å¹¶è¡Œç›‘å¬æ‰€æœ‰ %d ä¸ª FLOW", numFlows)

	// Channel for entries from all FLOWs
	entryChan := make(chan *FlowEntry, 100)

	// Launch a goroutine per FLOW
	var wg sync.WaitGroup
	for i := 0; i < numFlows; i++ {
		wg.Add(1)
		go r.readFlowJournal(i, entryChan, &wg)
	}

	// Close the channel once every FLOW goroutine exits
	go func() {
		wg.Wait()
		close(entryChan)
	}()

	// Main processing loop
	entriesCount := 0
	currentDB := uint64(0)
	flowStats := make(map[int]int) // entries per FLOW

	for flowEntry := range entryChan {
		// Handle errors
		if flowEntry.Error != nil {
			log.Printf("  âœ— FLOW-%d é”™è¯¯: %v", flowEntry.FlowID, flowEntry.Error)
			continue
		}

		entriesCount++
		flowStats[flowEntry.FlowID]++
		entry := flowEntry.Entry

		// Track current database
		if entry.Opcode == OpSelect {
			currentDB = entry.DbIndex
		}

		// Display decoded command
		r.displayFlowEntry(flowEntry.FlowID, entry, currentDB, entriesCount)

		// Replay command to Redis Cluster
		r.replayStats.mu.Lock()
		r.replayStats.TotalCommands++
		r.replayStats.mu.Unlock()

		if err := r.replayCommand(flowEntry.FlowID, entry); err != nil {
			log.Printf("  âœ— é‡æ”¾å¤±è´¥: %v", err)
		}

		// Attempt automatic checkpoint save
		r.tryAutoSaveCheckpoint()

		// Log statistics every 50 entries
		if entriesCount%50 == 0 {
			r.replayStats.mu.Lock()
			log.Printf("  ğŸ“Š ç»Ÿè®¡: æ€»è®¡=%d, æˆåŠŸ=%d, è·³è¿‡=%d, å¤±è´¥=%d",
				r.replayStats.TotalCommands,
				r.replayStats.ReplayedOK,
				r.replayStats.Skipped,
				r.replayStats.Failed)

			// Report per-FLOW stats
			for fid, count := range flowStats {
				lsn := r.replayStats.FlowLSNs[fid]
				log.Printf("    FLOW-%d: %d æ¡, LSN=%d", fid, count, lsn)
			}
			r.replayStats.mu.Unlock()
		}
	}

	log.Println("  â€¢ æ‰€æœ‰ FLOW çš„ Journal æµå·²ç»“æŸ")

	// Persist final checkpoint if enabled
	if r.cfg.Checkpoint.Enabled {
		log.Println("  ğŸ’¾ ä¿å­˜æœ€ç»ˆ checkpoint...")
		if err := r.saveCheckpoint(); err != nil {
			log.Printf("  âš  ä¿å­˜æœ€ç»ˆ checkpoint å¤±è´¥: %v", err)
		} else {
			log.Println("  âœ“ Checkpoint å·²ä¿å­˜")
		}
	}

	return nil
}

// readFlowJournal reads the journal stream for a specific FLOW
func (r *Replicator) readFlowJournal(flowID int, entryChan chan<- *FlowEntry, wg *sync.WaitGroup) {
	defer wg.Done()

	reader := NewJournalReader(r.flowConns[flowID])
	log.Printf("  [FLOW-%d] å¼€å§‹æ¥æ”¶ Journal æµ", flowID)

	for {
		// Observe cancellation
		select {
		case <-r.ctx.Done():
			log.Printf("  [FLOW-%d] æ”¶åˆ°åœæ­¢ä¿¡å·", flowID)
			return
		default:
		}

		// Read entry
		entry, err := reader.ReadEntry()
		if err != nil {
			if err == io.EOF {
				log.Printf("  [FLOW-%d] Journal æµç»“æŸï¼ˆEOFï¼‰", flowID)
				return
			}
			// Send error to channel
			entryChan <- &FlowEntry{
				FlowID: flowID,
				Error:  fmt.Errorf("è¯»å–å¤±è´¥: %w", err),
			}
			return
		}

		// Forward entry
		entryChan <- &FlowEntry{
			FlowID: flowID,
			Entry:  entry,
		}
	}
}

// displayFlowEntry prints a FLOW-tagged journal entry
func (r *Replicator) displayFlowEntry(flowID int, entry *JournalEntry, currentDB uint64, count int) {
	// Format output based on opcode
	switch entry.Opcode {
	case OpSelect:
		log.Printf("  [%d] FLOW-%d: SELECT DB=%d", count, flowID, entry.DbIndex)

	case OpLSN:
		log.Printf("  [%d] FLOW-%d: LSN %d", count, flowID, entry.LSN)

	case OpPing:
		log.Printf("  [%d] FLOW-%d: PING", count, flowID)

	case OpCommand:
		// Format arguments
		args := make([]string, len(entry.Args))
		for i, arg := range entry.Args {
			if len(arg) > 50 {
				args[i] = fmt.Sprintf("\"%s...\"", arg[:50])
			} else {
				args[i] = fmt.Sprintf("\"%s\"", arg)
			}
		}
		log.Printf("  [%d] FLOW-%d: %s %s (txid=%d, shards=%d)",
			count, flowID, entry.Command, strings.Join(args, " "), entry.TxID, entry.ShardCnt)

	case OpExpired:
		log.Printf("  [%d] FLOW-%d: EXPIRED %s (txid=%d)",
			count, flowID, entry.Command, entry.TxID)

	default:
		log.Printf("  [%d] FLOW-%d: %s", count, flowID, entry.Opcode)
	}
}

// displayEntry prints a decoded journal entry without FLOW context
func (r *Replicator) displayEntry(entry *JournalEntry, currentDB uint64, count int) {
	// Format output based on opcode
	switch entry.Opcode {
	case OpSelect:
		log.Printf("  [%d] SELECT DB=%d", count, entry.DbIndex)

	case OpLSN:
		log.Printf("  [%d] LSN %d", count, entry.LSN)

	case OpPing:
		log.Printf("  [%d] PING", count)

	case OpCommand:
		// Format arguments
		args := make([]string, len(entry.Args))
		for i, arg := range entry.Args {
			if len(arg) > 50 {
				args[i] = fmt.Sprintf("\"%s...\"", arg[:50])
			} else {
				args[i] = fmt.Sprintf("\"%s\"", arg)
			}
		}

		log.Printf("  [%d] DB=%d COMMAND %s %s",
			count, currentDB, entry.Command, strings.Join(args, " "))

	case OpExpired:
		args := make([]string, len(entry.Args))
		for i, arg := range entry.Args {
			if len(arg) > 50 {
				args[i] = fmt.Sprintf("\"%s...\"", arg[:50])
			} else {
				args[i] = fmt.Sprintf("\"%s\"", arg)
			}
		}

		log.Printf("  [%d] DB=%d EXPIRED %s %s",
			count, currentDB, entry.Command, strings.Join(args, " "))

	default:
		log.Printf("  [%d] %s", count, entry.String())
	}
}

// GetState returns the current replicator state
func (r *Replicator) GetState() ReplicaState {
	return r.state
}

// GetMasterInfo returns master metadata collected during handshake
func (r *Replicator) GetMasterInfo() MasterInfo {
	return r.masterInfo
}

// GetFlows returns all FLOW descriptors
func (r *Replicator) GetFlows() []FlowInfo {
	return r.flows
}

// ReplayStats holds command replay statistics
type ReplayStats struct {
	mu             sync.Mutex
	TotalCommands  int64
	ReplayedOK     int64
	Skipped        int64
	Failed         int64
	FlowLSNs       map[int]uint64 // latest LSN per FLOW
	LastReplayTime time.Time
}

// replayCommand replays a single journal command into Redis Cluster
func (r *Replicator) replayCommand(flowID int, entry *JournalEntry) error {
	switch entry.Opcode {
	case OpSelect:
		// Redis Cluster only exposes DB 0, ignore SELECT
		r.replayStats.mu.Lock()
		r.replayStats.Skipped++
		r.replayStats.mu.Unlock()
		return nil

	case OpPing:
		// Ignore heartbeat
		r.replayStats.mu.Lock()
		r.replayStats.Skipped++
		r.replayStats.mu.Unlock()
		return nil

	case OpLSN:
		// Track LSN only
		r.replayStats.mu.Lock()
		if r.replayStats.FlowLSNs == nil {
			r.replayStats.FlowLSNs = make(map[int]uint64)
		}
		r.replayStats.FlowLSNs[flowID] = entry.LSN
		r.replayStats.mu.Unlock()
		return nil

	case OpExpired:
		// Handle expired key by re-applying TTL using PEXPIRE
		if err := r.handleExpiredKey(entry); err != nil {
			r.replayStats.mu.Lock()
			r.replayStats.Failed++
			r.replayStats.mu.Unlock()
			return fmt.Errorf("å¤„ç†è¿‡æœŸé”®å¤±è´¥: %w", err)
		}
		r.replayStats.mu.Lock()
		r.replayStats.ReplayedOK++
		r.replayStats.LastReplayTime = time.Now()
		r.replayStats.mu.Unlock()
		return nil

	case OpCommand:
		// Check for global commands
		cmd := strings.ToUpper(entry.Command)
		if isGlobalCommand(cmd) {
			log.Printf("  âš  è·³è¿‡å…¨å±€å‘½ä»¤: %sï¼ˆéœ€è¦å¤šåˆ†ç‰‡åè°ƒï¼‰", cmd)
			r.replayStats.mu.Lock()
			r.replayStats.Skipped++
			r.replayStats.mu.Unlock()
			return nil
		}

		// Execute regular command
		if err := r.executeCommand(entry); err != nil {
			r.replayStats.mu.Lock()
			r.replayStats.Failed++
			r.replayStats.mu.Unlock()
			return fmt.Errorf("æ‰§è¡Œå‘½ä»¤å¤±è´¥: %w", err)
		}

		r.replayStats.mu.Lock()
		r.replayStats.ReplayedOK++
		r.replayStats.LastReplayTime = time.Now()
		r.replayStats.mu.Unlock()
		return nil

	default:
		return fmt.Errorf("æœªçŸ¥çš„ opcode: %d", entry.Opcode)
	}
}

// handleExpiredKey sets TTL for expired key events
func (r *Replicator) handleExpiredKey(entry *JournalEntry) error {
	if len(entry.Args) == 0 {
		return fmt.Errorf("EXPIRED å‘½ä»¤ç¼ºå°‘ key å‚æ•°")
	}

	key := entry.Args[0]

	// Assume TTL is 1ms (key already expired). Can be refined if Dragonfly publishes TTL.
	ttlMs := int64(1)

	_, err := r.clusterClient.Do("PEXPIRE", key, fmt.Sprintf("%d", ttlMs))
	if err != nil {
		return err
	}

	return nil
}

// executeCommand executes a journal command verbatim
func (r *Replicator) executeCommand(entry *JournalEntry) error {
	// Copy args
	args := make([]string, len(entry.Args))
	copy(args, entry.Args)

	// Execute
	_, err := r.clusterClient.Do(entry.Command, args...)
	return err
}

// isGlobalCommand checks if a command needs cluster-wide coordination
func isGlobalCommand(cmd string) bool {
	globalCmds := map[string]bool{
		"FLUSHDB":                true,
		"FLUSHALL":               true,
		"DFLYCLUSTER FLUSHSLOTS": true,
	}
	return globalCmds[cmd]
}

// saveCheckpoint persists the current checkpoint state
func (r *Replicator) saveCheckpoint() error {
	r.replayStats.mu.Lock()
	defer r.replayStats.mu.Unlock()

	// Build checkpoint payload
	cp := &checkpoint.Checkpoint{
		ReplicationID: r.masterInfo.ReplID,
		SessionID:     r.masterInfo.SyncID,
		NumFlows:      len(r.flows),
		FlowLSNs:      make(map[int]uint64),
	}

	// Copy FlowLSNs
	for flowID, lsn := range r.replayStats.FlowLSNs {
		cp.FlowLSNs[flowID] = lsn
	}

	// Save to file
	if err := r.checkpointMgr.Save(cp); err != nil {
		return fmt.Errorf("ä¿å­˜ checkpoint å¤±è´¥: %w", err)
	}

	r.lastCheckpointTime = time.Now()
	return nil
}

// tryAutoSaveCheckpoint periodically persists checkpoints
func (r *Replicator) tryAutoSaveCheckpoint() {
	// Skip when checkpointing is disabled
	if !r.cfg.Checkpoint.Enabled {
		return
	}

	if time.Since(r.lastCheckpointTime) >= r.checkpointInterval {
		if err := r.saveCheckpoint(); err != nil {
			log.Printf("  âš  è‡ªåŠ¨ä¿å­˜ checkpoint å¤±è´¥: %v", err)
		}
	}
}

// checkKeyConflict validates whether an RDB entry should be written based on conflict policy.
// Returns (write, error).
func (r *Replicator) checkKeyConflict(key string) (bool, error) {
	policy := r.cfg.Conflict.Policy

	// overwrite: always write
	if policy == "overwrite" {
		return true, nil
	}

	// panic/skip: check if key exists
	reply, err := r.clusterClient.Do("EXISTS", key)
	if err != nil {
		return false, fmt.Errorf("æ£€æŸ¥é”®å­˜åœ¨æ€§å¤±è´¥: %w", err)
	}

	exists, ok := reply.(int64)
	if !ok {
		return false, fmt.Errorf("EXISTS å‘½ä»¤è¿”å›ç±»å‹é”™è¯¯")
	}

	if exists == 0 {
		return true, nil // key does not exist
	}

	// Key exists
	if policy == "panic" {
		log.Printf("  âš ï¸ æ£€æµ‹åˆ°é‡å¤é”®: %s (policy=panicï¼Œç¨‹åºç»ˆæ­¢)", key)
		return false, fmt.Errorf("æ£€æµ‹åˆ°é‡å¤é”®: %s", key)
	}

	// policy == skip
	log.Printf("  âš ï¸ è·³è¿‡é‡å¤é”®: %s (policy=skip)", key)
	return false, nil
}

// writeRDBEntry writes an RDB entry into Redis
func (r *Replicator) writeRDBEntry(entry *RDBEntry) error {
	// Check conflicts
	shouldWrite, err := r.checkKeyConflict(entry.Key)
	if err != nil {
		return err // panic mode bubbles up
	}
	if !shouldWrite {
		return nil // skip mode simply ignores it
	}

	switch entry.Type {
	case RDB_TYPE_STRING:
		return r.writeString(entry)

	case RDB_TYPE_HASH, RDB_TYPE_HASH_ZIPLIST:
		return r.writeHash(entry)

	case RDB_TYPE_LIST_QUICKLIST_2, 18: // 18 is Dragonfly listpack encoding for lists
		return r.writeList(entry)

	case RDB_TYPE_SET, RDB_TYPE_SET_INTSET:
		return r.writeSet(entry)

	case RDB_TYPE_ZSET_2, RDB_TYPE_ZSET_ZIPLIST:
		return r.writeZSet(entry)

	default:
		return fmt.Errorf("æš‚ä¸æ”¯æŒçš„ RDB ç±»å‹: %d", entry.Type)
	}
}

// writeString handles string entries
func (r *Replicator) writeString(entry *RDBEntry) error {
	// Extract value
	strVal, ok := entry.Value.(*StringValue)
	if !ok {
		return fmt.Errorf("String ç±»å‹å€¼è½¬æ¢å¤±è´¥")
	}

	// Write value
	_, err := r.clusterClient.Do("SET", entry.Key, strVal.Value)
	if err != nil {
		return fmt.Errorf("SET å‘½ä»¤å¤±è´¥: %w", err)
	}

	// Apply TTL if needed
	if entry.ExpireMs > 0 {
		// Compute remaining TTL
		remainingMs := entry.ExpireMs - getCurrentTimeMillis()
		if remainingMs > 0 {
			_, err := r.clusterClient.Do("PEXPIRE", entry.Key, fmt.Sprintf("%d", remainingMs))
			if err != nil {
				return fmt.Errorf("PEXPIRE å‘½ä»¤å¤±è´¥: %w", err)
			}
		}
	}

	return nil
}

// writeHash handles hash entries
func (r *Replicator) writeHash(entry *RDBEntry) error {
	// Extract value
	hashVal, ok := entry.Value.(*HashValue)
	if !ok {
		return fmt.Errorf("Hash ç±»å‹å€¼è½¬æ¢å¤±è´¥")
	}

	// Remove existing key to avoid stale fields
	_, _ = r.clusterClient.Do("DEL", entry.Key)

	// Write all fields using HSET key field1 value1 ...
	log.Printf("  [DEBUG] writeHash: key=%s, fields=%d", entry.Key, len(hashVal.Fields))
	if len(hashVal.Fields) > 0 {
		args := []string{entry.Key}
		for field, value := range hashVal.Fields {
			args = append(args, field, value)
			log.Printf("  [DEBUG]   field=%s, value=%s", field, value)
		}
		log.Printf("  [DEBUG] æ‰§è¡Œ HSET å‘½ä»¤ï¼Œå‚æ•°æ•°é‡=%d", len(args))
		_, err := r.clusterClient.Do("HSET", args...)
		if err != nil {
			return fmt.Errorf("HSET å‘½ä»¤å¤±è´¥: %w", err)
		}
		log.Printf("  [DEBUG] HSET å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
	} else {
		log.Printf("  [DEBUG] å­—æ®µä¸ºç©ºï¼Œè·³è¿‡å†™å…¥")
	}

	// Apply TTL if needed
	if entry.ExpireMs > 0 {
		remainingMs := entry.ExpireMs - getCurrentTimeMillis()
		if remainingMs > 0 {
			_, err := r.clusterClient.Do("PEXPIRE", entry.Key, fmt.Sprintf("%d", remainingMs))
			if err != nil {
				return fmt.Errorf("PEXPIRE å‘½ä»¤å¤±è´¥: %w", err)
			}
		}
	}

	return nil
}

// writeList handles list entries
func (r *Replicator) writeList(entry *RDBEntry) error {
	// Extract value
	listVal, ok := entry.Value.(*ListValue)
	if !ok {
		return fmt.Errorf("List ç±»å‹å€¼è½¬æ¢å¤±è´¥")
	}

	// Remove existing key
	_, _ = r.clusterClient.Do("DEL", entry.Key)

	// Insert elements with RPUSH
	if len(listVal.Elements) > 0 {
		args := []string{entry.Key}
		for _, elem := range listVal.Elements {
			args = append(args, elem)
		}
		_, err := r.clusterClient.Do("RPUSH", args...)
		if err != nil {
			return fmt.Errorf("RPUSH å‘½ä»¤å¤±è´¥: %w", err)
		}
	}

	// Apply TTL
	if entry.ExpireMs > 0 {
		remainingMs := entry.ExpireMs - getCurrentTimeMillis()
		if remainingMs > 0 {
			_, err := r.clusterClient.Do("PEXPIRE", entry.Key, fmt.Sprintf("%d", remainingMs))
			if err != nil {
				return fmt.Errorf("PEXPIRE å‘½ä»¤å¤±è´¥: %w", err)
			}
		}
	}

	return nil
}

// writeSet handles set entries
func (r *Replicator) writeSet(entry *RDBEntry) error {
	// Extract value
	setVal, ok := entry.Value.(*SetValue)
	if !ok {
		return fmt.Errorf("Set ç±»å‹å€¼è½¬æ¢å¤±è´¥")
	}

	// Remove existing key
	_, _ = r.clusterClient.Do("DEL", entry.Key)

	// Insert members via SADD
	if len(setVal.Members) > 0 {
		args := []string{entry.Key}
		for _, member := range setVal.Members {
			args = append(args, member)
		}
		_, err := r.clusterClient.Do("SADD", args...)
		if err != nil {
			return fmt.Errorf("SADD å‘½ä»¤å¤±è´¥: %w", err)
		}
	}

	// Apply TTL
	if entry.ExpireMs > 0 {
		remainingMs := entry.ExpireMs - getCurrentTimeMillis()
		if remainingMs > 0 {
			_, err := r.clusterClient.Do("PEXPIRE", entry.Key, fmt.Sprintf("%d", remainingMs))
			if err != nil {
				return fmt.Errorf("PEXPIRE å‘½ä»¤å¤±è´¥: %w", err)
			}
		}
	}

	return nil
}

// writeZSet handles sorted set entries
func (r *Replicator) writeZSet(entry *RDBEntry) error {
	// Extract value
	zsetVal, ok := entry.Value.(*ZSetValue)
	if !ok {
		return fmt.Errorf("ZSet ç±»å‹å€¼è½¬æ¢å¤±è´¥")
	}

	// Remove existing key
	_, _ = r.clusterClient.Do("DEL", entry.Key)

	// Insert members via ZADD key score member ...
	if len(zsetVal.Members) > 0 {
		args := []string{entry.Key}
		for _, zm := range zsetVal.Members {
			args = append(args, fmt.Sprintf("%f", zm.Score), zm.Member)
		}
		_, err := r.clusterClient.Do("ZADD", args...)
		if err != nil {
			return fmt.Errorf("ZADD å‘½ä»¤å¤±è´¥: %w", err)
		}
	}

	// Apply TTL
	if entry.ExpireMs > 0 {
		remainingMs := entry.ExpireMs - getCurrentTimeMillis()
		if remainingMs > 0 {
			_, err := r.clusterClient.Do("PEXPIRE", entry.Key, fmt.Sprintf("%d", remainingMs))
			if err != nil {
				return fmt.Errorf("PEXPIRE å‘½ä»¤å¤±è´¥: %w", err)
			}
		}
	}

	return nil
}
